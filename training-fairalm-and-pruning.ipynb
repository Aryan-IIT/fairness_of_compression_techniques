{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":37705,"sourceType":"datasetVersion","datasetId":29561},{"sourceId":141592,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":119945,"modelId":143179},{"sourceId":169970,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":144601,"modelId":167163}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-18T08:54:31.864415Z","iopub.execute_input":"2024-11-18T08:54:31.865327Z","iopub.status.idle":"2024-11-18T08:54:31.870417Z","shell.execute_reply.started":"2024-11-18T08:54:31.865281Z","shell.execute_reply":"2024-11-18T08:54:31.869402Z"},"trusted":true},"outputs":[],"execution_count":64},{"cell_type":"code","source":"print(\"hello world\")","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:31.871963Z","iopub.execute_input":"2024-11-18T08:54:31.872268Z","iopub.status.idle":"2024-11-18T08:54:31.882158Z","shell.execute_reply.started":"2024-11-18T08:54:31.872236Z","shell.execute_reply":"2024-11-18T08:54:31.881300Z"},"trusted":true},"outputs":[{"name":"stdout","text":"hello world\n","output_type":"stream"}],"execution_count":65},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\n\nimport timm\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport sys\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:31.883924Z","iopub.execute_input":"2024-11-18T08:54:31.884242Z","iopub.status.idle":"2024-11-18T08:54:31.891199Z","shell.execute_reply.started":"2024-11-18T08:54:31.884210Z","shell.execute_reply":"2024-11-18T08:54:31.890300Z"},"trusted":true},"outputs":[],"execution_count":66},{"cell_type":"code","source":"from PIL import Image  # Importing the Image module\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:31.892324Z","iopub.execute_input":"2024-11-18T08:54:31.892680Z","iopub.status.idle":"2024-11-18T08:54:31.904382Z","shell.execute_reply.started":"2024-11-18T08:54:31.892636Z","shell.execute_reply":"2024-11-18T08:54:31.903561Z"},"trusted":true},"outputs":[],"execution_count":67},{"cell_type":"markdown","source":"# Hyperparameters ","metadata":{}},{"cell_type":"code","source":"##########################\n### SETTINGS\n##########################\n\n# Hyperparameters\nRANDOM_SEED = 1\n\n# Dynamically set device\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {DEVICE}\")\n\nGRAYSCALE = False","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:31.906451Z","iopub.execute_input":"2024-11-18T08:54:31.907080Z","iopub.status.idle":"2024-11-18T08:54:31.914200Z","shell.execute_reply.started":"2024-11-18T08:54:31.907038Z","shell.execute_reply":"2024-11-18T08:54:31.913289Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"train_size = int(10000*.8)\nvalidation_size = int(10000*.1)\ntest_size = int(10000*.1)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:31.915110Z","iopub.execute_input":"2024-11-18T08:54:31.915384Z","iopub.status.idle":"2024-11-18T08:54:31.930982Z","shell.execute_reply.started":"2024-11-18T08:54:31.915353Z","shell.execute_reply":"2024-11-18T08:54:31.930067Z"},"trusted":true},"outputs":[],"execution_count":69},{"cell_type":"code","source":"# import argparse\n# import os\n\n# import numpy as np\n# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n# import torch.optim as optim\n# from torchvision import datasets, transforms\n# from tqdm import tqdm\n\n# from net.models import LeNet\n# from net.quantization import apply_weight_sharing\n# import util\n\n# os.makedirs('saves', exist_ok=True)\n\n# # Training settings\n# parser = argparse.ArgumentParser(description='PyTorch MNIST pruning from deep compression paper')\n# parser.add_argument('--batch-size', type=int, default=50, metavar='N',\n#                     help='input batch size for training (default: 50)')\n# parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n#                     help='input batch size for testing (default: 1000)')\n# parser.add_argument('--epochs', type=int, default=100, metavar='N',\n#                     help='number of epochs to train (default: 100)')\n# parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n#                     help='learning rate (default: 0.01)')\n# parser.add_argument('--no-cuda', action='store_true', default=False,\n#                     help='disables CUDA training')\n# parser.add_argument('--seed', type=int, default=42, metavar='S',\n#                     help='random seed (default: 42)')\n# parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n#                     help='how many batches to wait before logging training status')\n# parser.add_argument('--log', type=str, default='log.txt',\n#                     help='log file name')\n# parser.add_argument('--sensitivity', type=float, default=2,\n#                     help=\"sensitivity value that is multiplied to layer's std in order to get threshold value\")\n# args = parser.parse_args()\n\n# # Control Seed\n# torch.manual_seed(args.seed)\n\n# # Select Device\n# use_cuda = not args.no_cuda and torch.cuda.is_available()\n# device = torch.device(\"cuda\" if use_cuda else 'cpu')\n# if use_cuda:\n#     print(\"Using CUDA!\")\n#     torch.cuda.manual_seed(args.seed)\n# else:\n#     print('Not using CUDA!!!')\n\n# # Loader\n# kwargs = {'num_workers': 5, 'pin_memory': True} if use_cuda else {}\n# train_loader = torch.utils.data.DataLoader(\n#     datasets.MNIST('data', train=True, download=True,\n#                    transform=transforms.Compose([\n#                        transforms.ToTensor(),\n#                        transforms.Normalize((0.1307,), (0.3081,))\n#                    ])),\n#     batch_size=args.batch_size, shuffle=True, **kwargs)\n# test_loader = torch.utils.data.DataLoader(\n#     datasets.MNIST('data', train=False, transform=transforms.Compose([\n#                        transforms.ToTensor(),\n#                        transforms.Normalize((0.1307,), (0.3081,))\n#                    ])),\n#     batch_size=args.test_batch_size, shuffle=False, **kwargs)\n\n\n# # Define which model to use\n# model = LeNet(mask=True).to(device)\n\n# print(model)\n# util.print_model_parameters(model)\n\n# # NOTE : `weight_decay` term denotes L2 regularization loss term\n# optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=0.0001)\n# initial_optimizer_state_dict = optimizer.state_dict()\n\n# def train(epochs):\n#     model.train()\n#     for epoch in range(epochs):\n#         pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n#         for batch_idx, (data, target) in pbar:\n#             data, target = data.to(device), target.to(device)\n#             optimizer.zero_grad()\n#             output = model(data)\n#             loss = F.nll_loss(output, target)\n#             loss.backward()\n\n#             # zero-out all the gradients corresponding to the pruned connections\n#             for name, p in model.named_parameters():\n#                 if 'mask' in name:\n#                     continue\n#                 tensor = p.data.cpu().numpy()\n#                 grad_tensor = p.grad.data.cpu().numpy()\n#                 grad_tensor = np.where(tensor==0, 0, grad_tensor)\n#                 p.grad.data = torch.from_numpy(grad_tensor).to(device)\n\n#             optimizer.step()\n#             if batch_idx % args.log_interval == 0:\n#                 done = batch_idx * len(data)\n#                 percentage = 100. * batch_idx / len(train_loader)\n#                 pbar.set_description(f'Train Epoch: {epoch} [{done:5}/{len(train_loader.dataset)} ({percentage:3.0f}%)]  Loss: {loss.item():.6f}')\n\n\n# def test():\n#     model.eval()\n#     test_loss = 0\n#     correct = 0\n#     with torch.no_grad():\n#         for data, target in test_loader:\n#             data, target = data.to(device), target.to(device)\n#             output = model(data)\n#             test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n#             pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n#             correct += pred.eq(target.data.view_as(pred)).sum().item()\n\n#         test_loss /= len(test_loader.dataset)\n#         accuracy = 100. * correct / len(test_loader.dataset)\n#         print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)')\n#     return accuracy\n\n\n# # Initial training\n# print(\"--- Initial training ---\")\n# train(args.epochs)\n# accuracy = test()\n# util.log(args.log, f\"initial_accuracy {accuracy}\")\n# torch.save(model, f\"saves/initial_model.ptmodel\")\n# print(\"--- Before pruning ---\")\n# util.print_nonzeros(model)\n\n# # Pruning\n# model.prune_by_std(args.sensitivity)\n# accuracy = test()\n# util.log(args.log, f\"accuracy_after_pruning {accuracy}\")\n# print(\"--- After pruning ---\")\n# util.print_nonzeros(model)\n\n# # Retrain\n# print(\"--- Retraining ---\")\n# optimizer.load_state_dict(initial_optimizer_state_dict) # Reset the optimizer\n# train(args.epochs)\n# torch.save(model, f\"saves/model_after_retraining.ptmodel\")\n# accuracy = test()\n# util.log(args.log, f\"accuracy_after_retraining {accuracy}\")\n\n# print(\"--- After Retraining ---\")\n# util.print_nonzeros(model)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:31.981554Z","iopub.execute_input":"2024-11-18T08:54:31.981849Z","iopub.status.idle":"2024-11-18T08:54:31.991817Z","shell.execute_reply.started":"2024-11-18T08:54:31.981817Z","shell.execute_reply":"2024-11-18T08:54:31.990951Z"},"trusted":true},"outputs":[],"execution_count":70},{"cell_type":"markdown","source":"# Model development and Fine-tuning","metadata":{}},{"cell_type":"code","source":"# import torchvision.models as models\n\n# model = models.resnet18()\n\n\n# model_path = \"/kaggle/input/resnet18_baseline_celeba/pytorch/default/1/fine_tuned_best_ever_resnet18\"\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:31.993497Z","iopub.execute_input":"2024-11-18T08:54:31.993779Z","iopub.status.idle":"2024-11-18T08:54:32.003702Z","shell.execute_reply.started":"2024-11-18T08:54:31.993749Z","shell.execute_reply":"2024-11-18T08:54:32.002792Z"},"trusted":true},"outputs":[],"execution_count":71},{"cell_type":"code","source":"import torchvision.models as models\n\nmodel = models.resnet18()\n\n\nmodel_path = \"/kaggle/input/resnet18_baseline_celeba/pytorch/default/1/fine_tuned_best_ever_resnet18\"\n\n# Freeze all the pre-trained layers\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Modify the last layer of the model\nnum_classes = 2 # replace with the number of classes in your dataset\nmodel.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n\n# # Freeze all the pre-trained layers\n# for param in model.fc.parameters():\n#     param.requires_grad = True\n\nfor name, param in model.named_parameters():\n    if \"layer4\" in name or \"fc\" in name:\n        param.requires_grad = True\n\nmodel.load_state_dict(torch.load(model_path))","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:32.004919Z","iopub.execute_input":"2024-11-18T08:54:32.005213Z","iopub.status.idle":"2024-11-18T08:54:32.280081Z","shell.execute_reply.started":"2024-11-18T08:54:32.005182Z","shell.execute_reply":"2024-11-18T08:54:32.279117Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/460664334.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path))\n","output_type":"stream"},{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":72},{"cell_type":"code","source":"# # Modify the last layer of the model\n# num_classes = 2 # replace with the number of classes in your dataset\n# model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n\n# # Freeze all the pre-trained layers\n# for param in model.fc.parameters():\n#     param.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:32.281370Z","iopub.execute_input":"2024-11-18T08:54:32.281759Z","iopub.status.idle":"2024-11-18T08:54:32.286159Z","shell.execute_reply.started":"2024-11-18T08:54:32.281716Z","shell.execute_reply":"2024-11-18T08:54:32.285232Z"},"trusted":true},"outputs":[],"execution_count":73},{"cell_type":"code","source":"# model.load_state_dict(torch.load(model_path))","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:32.288659Z","iopub.execute_input":"2024-11-18T08:54:32.289041Z","iopub.status.idle":"2024-11-18T08:54:32.294873Z","shell.execute_reply.started":"2024-11-18T08:54:32.289008Z","shell.execute_reply":"2024-11-18T08:54:32.293979Z"},"trusted":true},"outputs":[],"execution_count":74},{"cell_type":"markdown","source":"# Dataset Loaders\nThe target label is attractiveness and protected attribute is gender.","metadata":{}},{"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\n\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nfrom torchvision import datasets\nfrom torchvision import transforms\n\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:32.296150Z","iopub.execute_input":"2024-11-18T08:54:32.296779Z","iopub.status.idle":"2024-11-18T08:54:32.304087Z","shell.execute_reply.started":"2024-11-18T08:54:32.296746Z","shell.execute_reply":"2024-11-18T08:54:32.303291Z"},"trusted":true},"outputs":[],"execution_count":75},{"cell_type":"code","source":"#The target label is attractiveness and protected attribute is gender.\n\ndata_root = \"/kaggle/input/celeba-dataset/\"\nlabel_attr = \"Attractive\"\nprotected_attr = \"Male\"","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:32.305135Z","iopub.execute_input":"2024-11-18T08:54:32.305480Z","iopub.status.idle":"2024-11-18T08:54:32.312528Z","shell.execute_reply.started":"2024-11-18T08:54:32.305439Z","shell.execute_reply":"2024-11-18T08:54:32.311643Z"},"trusted":true},"outputs":[],"execution_count":76},{"cell_type":"code","source":"pd.read_csv(data_root + 'list_attr_celeba.csv').columns","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:32.313541Z","iopub.execute_input":"2024-11-18T08:54:32.313810Z","iopub.status.idle":"2024-11-18T08:54:33.148874Z","shell.execute_reply.started":"2024-11-18T08:54:32.313781Z","shell.execute_reply":"2024-11-18T08:54:33.147838Z"},"trusted":true},"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"Index(['image_id', '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive',\n       'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose',\n       'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows',\n       'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair',\n       'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open',\n       'Mustache', 'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin',\n       'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns',\n       'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings',\n       'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace',\n       'Wearing_Necktie', 'Young'],\n      dtype='object')"},"metadata":{}}],"execution_count":77},{"cell_type":"code","source":"df1 = pd.read_csv(data_root + 'list_attr_celeba.csv', usecols=[label_attr, protected_attr])\ndf1.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:33.149952Z","iopub.execute_input":"2024-11-18T08:54:33.150273Z","iopub.status.idle":"2024-11-18T08:54:33.595531Z","shell.execute_reply.started":"2024-11-18T08:54:33.150233Z","shell.execute_reply":"2024-11-18T08:54:33.594594Z"},"trusted":true},"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"   Attractive  Male\n0           1    -1\n1          -1    -1\n2          -1     1\n3           1    -1\n4           1    -1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Attractive</th>\n      <th>Male</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":78},{"cell_type":"code","source":"df1.loc[df1[label_attr] == -1, label_attr] = 0\ndf1.loc[df1[protected_attr] == -1, protected_attr] = 0\ndf1.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:33.597039Z","iopub.execute_input":"2024-11-18T08:54:33.597775Z","iopub.status.idle":"2024-11-18T08:54:33.613415Z","shell.execute_reply.started":"2024-11-18T08:54:33.597729Z","shell.execute_reply":"2024-11-18T08:54:33.612549Z"},"trusted":true},"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"   Attractive  Male\n0           1     0\n1           0     0\n2           0     1\n3           1     0\n4           1     0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Attractive</th>\n      <th>Male</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":79},{"cell_type":"code","source":"df2 = pd.read_csv(data_root + 'list_eval_partition.csv')\n\ndf2.columns = ['Filename', 'Partition']\nimage_series = df2['Filename']\ndf1 = df1.set_index(image_series)\ndf2 = df2.set_index('Filename')\ndf2.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:33.614416Z","iopub.execute_input":"2024-11-18T08:54:33.614691Z","iopub.status.idle":"2024-11-18T08:54:33.746372Z","shell.execute_reply.started":"2024-11-18T08:54:33.614660Z","shell.execute_reply":"2024-11-18T08:54:33.745504Z"},"trusted":true},"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"            Partition\nFilename             \n000001.jpg          0\n000002.jpg          0\n000003.jpg          0\n000004.jpg          0\n000005.jpg          0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Partition</th>\n    </tr>\n    <tr>\n      <th>Filename</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>000001.jpg</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>000002.jpg</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>000003.jpg</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>000004.jpg</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>000005.jpg</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":80},{"cell_type":"code","source":"pd.concat([df1, df2], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:33.747475Z","iopub.execute_input":"2024-11-18T08:54:33.747807Z","iopub.status.idle":"2024-11-18T08:54:33.805222Z","shell.execute_reply.started":"2024-11-18T08:54:33.747773Z","shell.execute_reply":"2024-11-18T08:54:33.804187Z"},"trusted":true},"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"            Attractive  Male  Partition\nFilename                               \n000001.jpg           1     0          0\n000002.jpg           0     0          0\n000003.jpg           0     1          0\n000004.jpg           1     0          0\n000005.jpg           1     0          0\n...                ...   ...        ...\n202595.jpg           1     0          2\n202596.jpg           0     1          2\n202597.jpg           0     1          2\n202598.jpg           1     0          2\n202599.jpg           1     0          2\n\n[202599 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Attractive</th>\n      <th>Male</th>\n      <th>Partition</th>\n    </tr>\n    <tr>\n      <th>Filename</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>000001.jpg</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>000002.jpg</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>000003.jpg</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>000004.jpg</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>000005.jpg</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>202595.jpg</th>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>202596.jpg</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>202597.jpg</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>202598.jpg</th>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>202599.jpg</th>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>202599 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":81},{"cell_type":"code","source":"# Hyper-params\nBATCH_SIZE = 256","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:33.806330Z","iopub.execute_input":"2024-11-18T08:54:33.806658Z","iopub.status.idle":"2024-11-18T08:54:33.810770Z","shell.execute_reply.started":"2024-11-18T08:54:33.806624Z","shell.execute_reply":"2024-11-18T08:54:33.809816Z"},"trusted":true},"outputs":[],"execution_count":82},{"cell_type":"code","source":"class CelebaDataset(Dataset):\n    \n    def __init__(self, csv_path, img_dir, transform=None, label_attr = 'Attractive', protected_attr = 'Male'):\n        \n        df = pd.read_csv(csv_path, index_col=0)\n        self.img_dir = img_dir\n        self.csv_path = csv_path\n        self.img_names = df.index.values\n        self.y = df[label_attr].values\n        self.p = df[protected_attr].values\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        img = Image.open(os.path.join(self.img_dir,\n                      self.img_names[index]))\n\n        if self.transform is not None:\n            img = self.transform(img)\n            \n        label = self.y[index]\n        protected = self.p[index]\n        return img, label, protected\n        \n    def __len__(self):\n        return self.y.shape[0]\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:33.816183Z","iopub.execute_input":"2024-11-18T08:54:33.816472Z","iopub.status.idle":"2024-11-18T08:54:33.824554Z","shell.execute_reply.started":"2024-11-18T08:54:33.816441Z","shell.execute_reply":"2024-11-18T08:54:33.823659Z"},"trusted":true},"outputs":[],"execution_count":83},{"cell_type":"code","source":"other_data_root = '/kaggle/working/' #for writing purposes","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:33.825631Z","iopub.execute_input":"2024-11-18T08:54:33.826000Z","iopub.status.idle":"2024-11-18T08:54:33.834126Z","shell.execute_reply.started":"2024-11-18T08:54:33.825958Z","shell.execute_reply":"2024-11-18T08:54:33.833220Z"},"trusted":true},"outputs":[],"execution_count":84},{"cell_type":"code","source":"def prepare_dataset(label_attr = 'Attractive', protected_attr = 'Male'):\n\n    print('Using label attribute:', label_attr)\n\n    df1 = pd.read_csv(data_root + 'list_attr_celeba.csv',usecols=[label_attr, protected_attr])\n    # Make 0 (female) & 1 (male) labels instead of -1 & 1\n    df1.loc[df1[label_attr] == -1, label_attr] = 0\n    df1.loc[df1[protected_attr] == -1, protected_attr] = 0\n    \n#     print(f\"df1\\n{df1}\")\n\n    df2 = pd.read_csv(data_root + 'list_eval_partition.csv')\n    df2.columns = ['image_id', 'partition']\n    image_series = df2['image_id']\n    df2 = df2.set_index('image_id')\n#     print(f\"df2\\n{df2}\")\n\n#     print(\"\\n\\n\")\n#     print(f\"df2 shape {df2.shape} and df1 shape {df1.shape}\")\n\n    df1 = df1.set_index(image_series)\n\n#     df3 = df1.merge(df2, left_index=True, right_index=True)\n    df3 = pd.concat([df1,df2],axis=1)\n#     print(\"\\n\\n\\n\\n\")\n#     print(df1.index)  \n#     print(df2.index)\n#     print(\"\\n\\n\\n\\n\")\n    \n#     print(f\"alt df3 \\n{ df1.merge(df2, left_index=True, right_index=True)}\")\n#     print(f\"df3\\n{df3}\")\n\n    \n    \n    \n    df3.to_csv(other_data_root + 'celeba-attractive-partitions.csv')\n#     print(df3)\n#     print(pd.read_csv(new_data_root+'celeba-attractive-partitions.csv'))\n    df4 = pd.read_csv(other_data_root + 'celeba-attractive-partitions.csv', index_col=0)\n\n    df4.loc[df4['partition'] == 0].to_csv(other_data_root + 'celeba-attractive-train.csv')\n    df4.loc[df4['partition'] == 1].to_csv(other_data_root + 'celeba-attractive-valid.csv')\n    df4.loc[df4['partition'] == 2].to_csv(other_data_root + 'celeba-attractive-test.csv')\n    \n#     print(f\"Train samples: {df4.loc[df4['partition'] == 0].shape[0]}\")\n#     print(f\"Valid samples: {df4.loc[df4['partition'] == 1].shape[0]}\")\n#     print(f\"Test samples: {df4.loc[df4['partition'] == 2].shape[0]}\")\n\n    \ndef get_loaders():\n\n    prepare_dataset(label_attr, protected_attr)\n    \n    # Note that transforms.ToTensor()\n    # already divides pixels by 255. internally\n\n    custom_transform = transforms.Compose([transforms.CenterCrop((178, 178)),\n                                           transforms.Resize((128, 128)),\n                                           transforms.ToTensor()])\n\n    train_dataset = CelebaDataset(csv_path=other_data_root + 'celeba-attractive-train.csv',\n                                  img_dir=data_root + 'img_align_celeba/img_align_celeba',\n                                  transform=custom_transform,\n                                  label_attr=label_attr,\n                                  protected_attr = protected_attr)\n\n    valid_dataset = CelebaDataset(csv_path=other_data_root + 'celeba-attractive-valid.csv',\n                                  img_dir=data_root + 'img_align_celeba/img_align_celeba',\n                                  transform=custom_transform,\n                                  label_attr=label_attr,\n                                  protected_attr = protected_attr)\n\n    test_dataset = CelebaDataset(csv_path=other_data_root + 'celeba-attractive-test.csv',\n                                 img_dir=data_root + 'img_align_celeba/img_align_celeba',\n                                 transform=custom_transform,\n                                 label_attr=label_attr,\n                                 protected_attr = protected_attr)\n\n    train_loader = DataLoader(dataset=train_dataset,\n                              batch_size=BATCH_SIZE,\n                              shuffle=True,\n                              num_workers=4)\n\n    valid_loader = DataLoader(dataset=valid_dataset,\n                              batch_size=BATCH_SIZE,\n                              shuffle=False,\n                              num_workers=4)\n    \n    test_loader = DataLoader(dataset=test_dataset,\n                             batch_size=BATCH_SIZE,\n                             shuffle=False,\n                             num_workers=4)\n\n    return train_loader, valid_loader, test_loader\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:33.835618Z","iopub.execute_input":"2024-11-18T08:54:33.835942Z","iopub.status.idle":"2024-11-18T08:54:33.850150Z","shell.execute_reply.started":"2024-11-18T08:54:33.835887Z","shell.execute_reply":"2024-11-18T08:54:33.849209Z"},"trusted":true},"outputs":[],"execution_count":85},{"cell_type":"markdown","source":"## main.py running ","metadata":{}},{"cell_type":"markdown","source":"### Few libraries","metadata":{}},{"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\n\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nfrom torchvision import datasets\nfrom torchvision import transforms\n\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:33.851050Z","iopub.execute_input":"2024-11-18T08:54:33.851325Z","iopub.status.idle":"2024-11-18T08:54:33.862248Z","shell.execute_reply.started":"2024-11-18T08:54:33.851294Z","shell.execute_reply":"2024-11-18T08:54:33.861408Z"},"trusted":true},"outputs":[],"execution_count":86},{"cell_type":"code","source":"# from datasets_celebA import get_loaders\n# from resnet import resnet18\n\n# from utils import *\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:33.863613Z","iopub.execute_input":"2024-11-18T08:54:33.864125Z","iopub.status.idle":"2024-11-18T08:54:33.873693Z","shell.execute_reply.started":"2024-11-18T08:54:33.864082Z","shell.execute_reply":"2024-11-18T08:54:33.872843Z"},"trusted":true},"outputs":[],"execution_count":87},{"cell_type":"markdown","source":"### configuration","metadata":{}},{"cell_type":"code","source":"config = {}\n# # Option to choose between different algorithms\n# config['ALGORITHM'] = 'FAIR_ALM'  # 'FAIR_ALM' or 'L2_PENALTY' or 'NO_CONSTRAINTS' \n# config['CONSTRAINT'] = 'DEO' # DEO, DDP, PPV \n# config['LAM0_PRIOR'] = 0.\n# config['LAM1_PRIOR'] = 0.\n# config['LAM2_PRIOR'] = 0.\n# config['ETA_INIT'] = 20\n# config['ETA_BETA'] = 1.01\n# config['SAVE_CKPT'] = False\n# config['DEBUG'] = False\n\n# # storing checkpoints \n# config['file_name'] = '/kaggle/working/'","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:33.874974Z","iopub.execute_input":"2024-11-18T08:54:33.875628Z","iopub.status.idle":"2024-11-18T08:54:33.881883Z","shell.execute_reply.started":"2024-11-18T08:54:33.875585Z","shell.execute_reply":"2024-11-18T08:54:33.881076Z"},"trusted":true},"outputs":[],"execution_count":88},{"cell_type":"markdown","source":"### hyperparameters and architecture","metadata":{}},{"cell_type":"code","source":"# Hyperparameters\nconfig['LR'] = 0.0001\nconfig['NUM_EPOCHS'] = 25\nconfig['NUM_INNER'] = 5","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:33.882868Z","iopub.execute_input":"2024-11-18T08:54:33.883160Z","iopub.status.idle":"2024-11-18T08:54:33.891522Z","shell.execute_reply.started":"2024-11-18T08:54:33.883130Z","shell.execute_reply":"2024-11-18T08:54:33.890682Z"},"trusted":true},"outputs":[],"execution_count":89},{"cell_type":"code","source":"# Architecture\nNUM_FEATURES = 128*128\nNUM_CLASSES = 2\nGRAYSCALE = False\n\nconfig['OPTIMIZER_'] = 'SGD'\nconfig['MODEL_'] = 'resnet18'\nconfig['SHUFFLE_'] = True","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:33.892479Z","iopub.execute_input":"2024-11-18T08:54:33.892801Z","iopub.status.idle":"2024-11-18T08:54:33.899797Z","shell.execute_reply.started":"2024-11-18T08:54:33.892763Z","shell.execute_reply":"2024-11-18T08:54:33.898953Z"},"trusted":true},"outputs":[],"execution_count":90},{"cell_type":"markdown","source":"### functions for training and pre-processing","metadata":{}},{"cell_type":"code","source":"def save_everything(epoch, net, optimizer, train_acc, val_acc):\n    # Save checkpoint.\n    state = {\n        'epoch': epoch,\n        'net': net.state_dict(),\n        'optimizer': optimizer.state_dict(),\n        'train_acc': train_acc,\n        'val_acc': val_acc\n    }\n    if not os.path.isdir(config['file_name']):\n        os.mkdir(config['file_name'])\n    torch.save(state, config['file_name'] + '/ckpt_' + str(epoch) + '.t7')","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:33.901279Z","iopub.execute_input":"2024-11-18T08:54:33.901539Z","iopub.status.idle":"2024-11-18T08:54:33.908280Z","shell.execute_reply.started":"2024-11-18T08:54:33.901511Z","shell.execute_reply":"2024-11-18T08:54:33.907416Z"},"trusted":true},"outputs":[],"execution_count":91},{"cell_type":"code","source":"train_loader, valid_loader, test_loader = get_loaders()\n#here model is already defined","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:33.909289Z","iopub.execute_input":"2024-11-18T08:54:33.909568Z","iopub.status.idle":"2024-11-18T08:54:35.569643Z","shell.execute_reply.started":"2024-11-18T08:54:33.909531Z","shell.execute_reply":"2024-11-18T08:54:35.568867Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Using label attribute: Attractive\n","output_type":"stream"}],"execution_count":92},{"cell_type":"code","source":"# #idk what this does\n# #### DATA PARALLEL START ####\n# if torch.cuda.device_count() > 1:\n# \tprint(\"Using\", torch.cuda.device_count(), \"GPUs\")\n# \tmodel = nn.DataParallel(model)\n# #### DATA PARALLEL END ####\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:35.570791Z","iopub.execute_input":"2024-11-18T08:54:35.571084Z","iopub.status.idle":"2024-11-18T08:54:35.575374Z","shell.execute_reply.started":"2024-11-18T08:54:35.571053Z","shell.execute_reply":"2024-11-18T08:54:35.574314Z"},"trusted":true},"outputs":[],"execution_count":93},{"cell_type":"code","source":"# model = model.cuda()\n# criterion = torch.nn.CrossEntropyLoss(reduce=False)\n# optimizer = torch.optim.SGD(model.parameters(), lr=config['LR'])","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:35.576351Z","iopub.execute_input":"2024-11-18T08:54:35.576616Z","iopub.status.idle":"2024-11-18T08:54:35.585212Z","shell.execute_reply.started":"2024-11-18T08:54:35.576586Z","shell.execute_reply":"2024-11-18T08:54:35.584399Z"},"trusted":true},"outputs":[],"execution_count":94},{"cell_type":"code","source":"# lam0 = config['LAM0_PRIOR'] \n# lam1 = config['LAM1_PRIOR']\n# lam2 = config['LAM2_PRIOR'] \n# eta = config['ETA_INIT']","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:35.587468Z","iopub.execute_input":"2024-11-18T08:54:35.587780Z","iopub.status.idle":"2024-11-18T08:54:35.595002Z","shell.execute_reply.started":"2024-11-18T08:54:35.587734Z","shell.execute_reply":"2024-11-18T08:54:35.594211Z"},"trusted":true},"outputs":[],"execution_count":95},{"cell_type":"code","source":"pd.DataFrame([config])","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:35.596035Z","iopub.execute_input":"2024-11-18T08:54:35.596373Z","iopub.status.idle":"2024-11-18T08:54:35.613181Z","shell.execute_reply.started":"2024-11-18T08:54:35.596342Z","shell.execute_reply":"2024-11-18T08:54:35.612325Z"},"trusted":true},"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"       LR  NUM_EPOCHS  NUM_INNER OPTIMIZER_    MODEL_  SHUFFLE_\n0  0.0001          25          5        SGD  resnet18      True","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LR</th>\n      <th>NUM_EPOCHS</th>\n      <th>NUM_INNER</th>\n      <th>OPTIMIZER_</th>\n      <th>MODEL_</th>\n      <th>SHUFFLE_</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0001</td>\n      <td>25</td>\n      <td>5</td>\n      <td>SGD</td>\n      <td>resnet18</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":96},{"cell_type":"markdown","source":"## Fine tuning","metadata":{}},{"cell_type":"code","source":"import time\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:35.614625Z","iopub.execute_input":"2024-11-18T08:54:35.614914Z","iopub.status.idle":"2024-11-18T08:54:35.622084Z","shell.execute_reply.started":"2024-11-18T08:54:35.614866Z","shell.execute_reply":"2024-11-18T08:54:35.621286Z"},"trusted":true},"outputs":[],"execution_count":97},{"cell_type":"code","source":"from torch.optim.lr_scheduler import ReduceLROnPlateau\n\n# Initialize scheduler\nscheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, verbose=True)\n\n# Early stopping variables\nbest_val_accuracy = 0.0\npatience = 5  # Stop if no improvement after 5 epochs\nepochs_without_improvement = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T08:54:35.623214Z","iopub.execute_input":"2024-11-18T08:54:35.623624Z","iopub.status.idle":"2024-11-18T08:54:35.631361Z","shell.execute_reply.started":"2024-11-18T08:54:35.623580Z","shell.execute_reply":"2024-11-18T08:54:35.630383Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":98},{"cell_type":"code","source":"config = {}\n# Option to choose between different algorithms\nconfig['ALGORITHM'] = 'FAIR_ALM'  # 'FAIR_ALM' or 'L2_PENALTY' or 'NO_CONSTRAINTS' \nconfig['CONSTRAINT'] = 'DEO' # DEO, DDP, PPV \nconfig['LAM0_PRIOR'] = 0.\nconfig['LAM1_PRIOR'] = 0.\nconfig['LAM2_PRIOR'] = 0.\nconfig['ETA_INIT'] = 20\nconfig['ETA_BETA'] = 1.01\nconfig['SAVE_CKPT'] = False\nconfig['DEBUG'] = False\n\n# Architecture\nNUM_FEATURES = 128*128\nNUM_CLASSES = 2\nGRAYSCALE = False\n# Hyperparameters\nconfig['LR'] = 0.001\nconfig['NUM_EPOCHS'] = 25\nconfig['NUM_INNER'] = 5\nconfig['OPTIMIZER_'] = 'SGD'\nconfig['MODEL_'] = 'resnet18'\nconfig['SHUFFLE_'] = True\n\nmodel = model.cuda()\ncriterion = torch.nn.CrossEntropyLoss(reduction='none')\noptimizer = torch.optim.SGD(model.parameters(), lr=config['LR'])\n\n#idk what this does\n#### DATA PARALLEL START ####\nif torch.cuda.device_count() > 1:\n\tprint(\"Using\", torch.cuda.device_count(), \"GPUs\")\n\tmodel = nn.DataParallel(model)\n#### DATA PARALLEL END ####\n\n\nlam0 = config['LAM0_PRIOR'] \nlam1 = config['LAM1_PRIOR']\nlam2 = config['LAM2_PRIOR'] \neta = config['ETA_INIT']\n\n\n# storing checkpoints \nconfig['file_name'] = '/kaggle/working/'\n\nstart_time = time.time()\n\nfor epoch in range(config['NUM_EPOCHS']):\n    eta *= config['ETA_BETA']  # Update dual parameter\n    model.train()\n\n    for batch_idx, (features, targets, protected) in enumerate(train_loader):\n        if config['DEBUG'] and batch_idx > 1:\n            break\n\n        features, targets, protected = features.cuda(), targets.cuda(), protected.cuda()\n        \n        if config['ALGORITHM'] == 'FAIR_ALM':\n            for _ in range(config['NUM_INNER']):\n                # preprocess = transforms.Compose([\n                #     transforms.Resize((224, 224)),\n                #     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n                # ])\n                input_tensor = torch.stack([image for image in features])\n                logits = model(input_tensor)\n\n                loss_all = criterion(logits, targets)\n                loss_t0_s0 = loss_all[(targets == 0) & (protected == 0)].mean()\n                loss_t0_s1 = loss_all[(targets == 0) & (protected == 1)].mean()\n                loss_t1_s0 = loss_all[(targets == 1) & (protected == 0)].mean()\n                loss_t1_s1 = loss_all[(targets == 1) & (protected == 1)].mean()\n                train_loss = loss_all.mean()\n                penalty_loss = loss_t1_s0 - loss_t1_s1\n\n                optimizer.zero_grad()\n                loss = (\n                    loss_all.mean() \n                    + (eta / 4 + (lam0 - lam1) / 2) * loss_t1_s0 \n                    + (eta / 4 + (lam1 - lam0) / 2) * loss_t1_s1\n                )\n                loss.backward()\n                optimizer.step()\n\n            lam0 = 0.5 * (lam0 - lam1) + 0.5 * eta * (loss_t1_s0.item() - loss_t1_s1.item())\n            lam1 = 0.5 * (lam1 - lam0) + 0.5 * eta * (loss_t1_s1.item() - loss_t1_s0.item())\n\n        if batch_idx % 50 == 0:\n            print(f\"Epoch: {epoch+1}/{config['NUM_EPOCHS']} | Batch: {batch_idx}/{len(train_loader)} \"\n                  f\"| Train Loss: {train_loss:.4f} | Penalty Loss: {penalty_loss:.4f}\")\n            print(f\"eta: {eta:.3f} | lam0: {lam0:.3f} | lam1: {lam1:.3f}\")\n\n    # Validation step\n    model.eval()\n    val_correct, val_total = 0, 0\n    with torch.no_grad():\n        for val_features, val_targets, _ in valid_loader:\n            val_features, val_targets = val_features.cuda(), val_targets.cuda()\n            val_logits = model(val_features)\n            val_preds = torch.argmax(val_logits, dim=1)\n            val_correct += (val_preds == val_targets).sum().item()\n            val_total += val_targets.size(0)\n\n    val_accuracy = val_correct / val_total\n    print(f\"Epoch {epoch+1}: Validation Accuracy: {val_accuracy:.4f}\")\n    \n    # Scheduler step\n    scheduler.step(val_accuracy)\n\n    # Early stopping\n    if val_accuracy > best_val_accuracy:\n        best_val_accuracy = val_accuracy\n        epochs_without_improvement = 0\n        # Optionally save the best model\n        if config['SAVE_CKPT']:\n            torch.save(model.state_dict(), config['file_name'] + 'best_model.pth')\n    else:\n        epochs_without_improvement += 1\n\n    if epochs_without_improvement >= patience:\n        print(f\"No improvement for {patience} epochs. Early stopping...\")\n        break\n\nprint(f\"Training completed in {time.time() - start_time:.2f} seconds.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T08:54:35.632700Z","iopub.execute_input":"2024-11-18T08:54:35.633045Z","iopub.status.idle":"2024-11-18T09:48:49.569819Z","shell.execute_reply.started":"2024-11-18T08:54:35.632996Z","shell.execute_reply":"2024-11-18T09:48:49.568675Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Using 2 GPUs\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 1/25 | Batch: 0/636 | Train Loss: 0.0241 | Penalty Loss: -0.0701\neta: 20.200 | lam0: -0.708 | lam1: 1.062\nEpoch: 1/25 | Batch: 50/636 | Train Loss: 0.0911 | Penalty Loss: 0.0006\neta: 20.200 | lam0: -2.242 | lam1: 2.230\nEpoch: 1/25 | Batch: 100/636 | Train Loss: 0.0534 | Penalty Loss: -0.0626\neta: 20.200 | lam0: -1.179 | lam1: 1.504\nEpoch: 1/25 | Batch: 150/636 | Train Loss: 0.0284 | Penalty Loss: 0.0036\neta: 20.200 | lam0: -2.519 | lam1: 2.507\nEpoch: 1/25 | Batch: 200/636 | Train Loss: 0.0276 | Penalty Loss: 0.0014\neta: 20.200 | lam0: -1.944 | lam1: 1.933\nEpoch: 1/25 | Batch: 250/636 | Train Loss: 0.0580 | Penalty Loss: -0.0009\neta: 20.200 | lam0: -1.683 | lam1: 1.681\nEpoch: 1/25 | Batch: 300/636 | Train Loss: 0.1260 | Penalty Loss: 0.0000\neta: 20.200 | lam0: -2.698 | lam1: 2.697\nEpoch: 1/25 | Batch: 350/636 | Train Loss: 0.0844 | Penalty Loss: 0.0008\neta: 20.200 | lam0: -1.325 | lam1: 1.322\nEpoch: 1/25 | Batch: 400/636 | Train Loss: 0.0680 | Penalty Loss: -0.0031\neta: 20.200 | lam0: -0.193 | lam1: 0.201\nEpoch: 1/25 | Batch: 450/636 | Train Loss: 0.0517 | Penalty Loss: 0.0004\neta: 20.200 | lam0: -1.767 | lam1: 1.771\nEpoch: 1/25 | Batch: 500/636 | Train Loss: 0.0239 | Penalty Loss: 0.0057\neta: 20.200 | lam0: -1.486 | lam1: 1.456\nEpoch: 1/25 | Batch: 550/636 | Train Loss: 0.0388 | Penalty Loss: 0.0037\neta: 20.200 | lam0: -1.671 | lam1: 1.597\nEpoch: 1/25 | Batch: 600/636 | Train Loss: 0.0150 | Penalty Loss: 0.0044\neta: 20.200 | lam0: 0.113 | lam1: -0.139\nEpoch 1: Validation Accuracy: 0.7913\nEpoch: 2/25 | Batch: 0/636 | Train Loss: 0.0464 | Penalty Loss: 0.0001\neta: 20.402 | lam0: -1.186 | lam1: 1.182\nEpoch: 2/25 | Batch: 50/636 | Train Loss: 0.0516 | Penalty Loss: 0.0187\neta: 20.402 | lam0: 1.094 | lam1: -1.192\nEpoch: 2/25 | Batch: 100/636 | Train Loss: 0.1285 | Penalty Loss: 0.0002\neta: 20.402 | lam0: 1.333 | lam1: -1.341\nEpoch: 2/25 | Batch: 150/636 | Train Loss: 0.1123 | Penalty Loss: -0.0004\neta: 20.402 | lam0: 1.170 | lam1: -1.176\nEpoch: 2/25 | Batch: 200/636 | Train Loss: 0.0226 | Penalty Loss: -0.0069\neta: 20.402 | lam0: 0.449 | lam1: -0.415\nEpoch: 2/25 | Batch: 250/636 | Train Loss: 0.0862 | Penalty Loss: -0.0013\neta: 20.402 | lam0: 0.790 | lam1: -0.784\nEpoch: 2/25 | Batch: 300/636 | Train Loss: 0.1046 | Penalty Loss: 0.0017\neta: 20.402 | lam0: 0.757 | lam1: -0.760\nEpoch: 2/25 | Batch: 350/636 | Train Loss: 0.0479 | Penalty Loss: -0.0000\neta: 20.402 | lam0: 1.389 | lam1: -1.390\nEpoch: 2/25 | Batch: 400/636 | Train Loss: 0.0624 | Penalty Loss: 0.0005\neta: 20.402 | lam0: 1.594 | lam1: -1.593\nEpoch: 2/25 | Batch: 450/636 | Train Loss: 0.0639 | Penalty Loss: -0.0017\neta: 20.402 | lam0: -0.441 | lam1: 0.480\nEpoch: 2/25 | Batch: 500/636 | Train Loss: 0.0647 | Penalty Loss: 0.0173\neta: 20.402 | lam0: 0.010 | lam1: -0.096\nEpoch: 2/25 | Batch: 550/636 | Train Loss: 0.0449 | Penalty Loss: 0.0003\neta: 20.402 | lam0: 0.794 | lam1: -0.798\nEpoch: 2/25 | Batch: 600/636 | Train Loss: 0.0890 | Penalty Loss: 0.0000\neta: 20.402 | lam0: 0.392 | lam1: -0.405\nEpoch 2: Validation Accuracy: 0.7865\nEpoch: 3/25 | Batch: 0/636 | Train Loss: 0.0822 | Penalty Loss: -0.0000\neta: 20.606 | lam0: -2.248 | lam1: 2.247\nEpoch: 3/25 | Batch: 50/636 | Train Loss: 0.0446 | Penalty Loss: -0.0004\neta: 20.606 | lam0: -1.970 | lam1: 1.988\nEpoch: 3/25 | Batch: 100/636 | Train Loss: 0.0785 | Penalty Loss: 0.0008\neta: 20.606 | lam0: -1.473 | lam1: 1.470\nEpoch: 3/25 | Batch: 150/636 | Train Loss: 0.0137 | Penalty Loss: 0.0001\neta: 20.606 | lam0: -1.066 | lam1: 1.066\nEpoch: 3/25 | Batch: 200/636 | Train Loss: 0.0618 | Penalty Loss: 0.0000\neta: 20.606 | lam0: -1.208 | lam1: 1.213\nEpoch: 3/25 | Batch: 250/636 | Train Loss: 0.0453 | Penalty Loss: -0.0001\neta: 20.606 | lam0: 0.508 | lam1: -0.547\nEpoch: 3/25 | Batch: 300/636 | Train Loss: 0.0112 | Penalty Loss: 0.0034\neta: 20.606 | lam0: 1.238 | lam1: -1.256\nEpoch: 3/25 | Batch: 350/636 | Train Loss: 0.1740 | Penalty Loss: 0.0011\neta: 20.606 | lam0: 1.273 | lam1: -1.278\nEpoch: 3/25 | Batch: 400/636 | Train Loss: 0.0494 | Penalty Loss: 0.0195\neta: 20.606 | lam0: 0.483 | lam1: -0.567\nEpoch: 3/25 | Batch: 450/636 | Train Loss: 0.0884 | Penalty Loss: -0.0029\neta: 20.606 | lam0: -0.966 | lam1: 0.975\nEpoch: 3/25 | Batch: 500/636 | Train Loss: 0.0525 | Penalty Loss: 0.0077\neta: 20.606 | lam0: -0.921 | lam1: 0.887\nEpoch: 3/25 | Batch: 550/636 | Train Loss: 0.0836 | Penalty Loss: 0.0000\neta: 20.606 | lam0: -1.026 | lam1: 1.019\nEpoch: 3/25 | Batch: 600/636 | Train Loss: 0.0528 | Penalty Loss: 0.0007\neta: 20.606 | lam0: -0.853 | lam1: 0.851\nEpoch 3: Validation Accuracy: 0.7910\nEpoch: 4/25 | Batch: 0/636 | Train Loss: 0.1074 | Penalty Loss: 0.0001\neta: 20.812 | lam0: -1.257 | lam1: 1.256\nEpoch: 4/25 | Batch: 50/636 | Train Loss: 0.0712 | Penalty Loss: -0.0002\neta: 20.812 | lam0: -1.531 | lam1: 1.532\nEpoch: 4/25 | Batch: 100/636 | Train Loss: 0.0581 | Penalty Loss: 0.0026\neta: 20.812 | lam0: 0.153 | lam1: -0.165\nEpoch: 4/25 | Batch: 150/636 | Train Loss: 0.0181 | Penalty Loss: 0.0004\neta: 20.812 | lam0: 1.250 | lam1: -1.247\nEpoch: 4/25 | Batch: 200/636 | Train Loss: 0.0477 | Penalty Loss: 0.0003\neta: 20.812 | lam0: 1.890 | lam1: -1.889\nEpoch: 4/25 | Batch: 250/636 | Train Loss: 0.0457 | Penalty Loss: -0.0006\neta: 20.812 | lam0: 1.882 | lam1: -1.879\nEpoch: 4/25 | Batch: 300/636 | Train Loss: 0.0287 | Penalty Loss: -0.0005\neta: 20.812 | lam0: 2.830 | lam1: -2.827\nEpoch: 4/25 | Batch: 350/636 | Train Loss: 0.0440 | Penalty Loss: -0.0005\neta: 20.812 | lam0: 2.568 | lam1: -2.551\nEpoch: 4/25 | Batch: 400/636 | Train Loss: 0.0730 | Penalty Loss: 0.0000\neta: 20.812 | lam0: 4.257 | lam1: -4.276\nEpoch: 4/25 | Batch: 450/636 | Train Loss: 0.0664 | Penalty Loss: 0.0019\neta: 20.812 | lam0: 3.325 | lam1: -3.356\nEpoch: 4/25 | Batch: 500/636 | Train Loss: 0.0553 | Penalty Loss: 0.0008\neta: 20.812 | lam0: 2.164 | lam1: -2.162\nEpoch: 4/25 | Batch: 550/636 | Train Loss: 0.0442 | Penalty Loss: -0.0105\neta: 20.812 | lam0: 1.403 | lam1: -1.348\nEpoch: 4/25 | Batch: 600/636 | Train Loss: 0.0611 | Penalty Loss: 0.0001\neta: 20.812 | lam0: 0.205 | lam1: -0.204\nEpoch 4: Validation Accuracy: 0.7920\nEpoch: 5/25 | Batch: 0/636 | Train Loss: 0.0335 | Penalty Loss: 0.0073\neta: 21.020 | lam0: -0.081 | lam1: 0.042\nEpoch: 5/25 | Batch: 50/636 | Train Loss: 0.0396 | Penalty Loss: -0.0003\neta: 21.020 | lam0: -2.499 | lam1: 2.500\nEpoch: 5/25 | Batch: 100/636 | Train Loss: 0.0426 | Penalty Loss: -0.0034\neta: 21.020 | lam0: -2.699 | lam1: 2.722\nEpoch: 5/25 | Batch: 150/636 | Train Loss: 0.0250 | Penalty Loss: 0.0010\neta: 21.020 | lam0: -1.650 | lam1: 1.645\nEpoch: 5/25 | Batch: 200/636 | Train Loss: 0.0538 | Penalty Loss: 0.0013\neta: 21.020 | lam0: 0.038 | lam1: -0.051\nEpoch: 5/25 | Batch: 250/636 | Train Loss: 0.0273 | Penalty Loss: 0.0028\neta: 21.020 | lam0: 0.845 | lam1: -0.863\nEpoch: 5/25 | Batch: 300/636 | Train Loss: 0.0602 | Penalty Loss: 0.0000\neta: 21.020 | lam0: 1.952 | lam1: -1.957\nEpoch: 5/25 | Batch: 350/636 | Train Loss: 0.0650 | Penalty Loss: -0.0006\neta: 21.020 | lam0: 2.877 | lam1: -2.874\nEpoch: 5/25 | Batch: 400/636 | Train Loss: 0.0745 | Penalty Loss: 0.0674\neta: 21.020 | lam0: 4.804 | lam1: -5.157\nEpoch: 5/25 | Batch: 450/636 | Train Loss: 0.0410 | Penalty Loss: 0.0309\neta: 21.020 | lam0: 4.321 | lam1: -4.483\nEpoch: 5/25 | Batch: 500/636 | Train Loss: 0.0300 | Penalty Loss: -0.0029\neta: 21.020 | lam0: 1.147 | lam1: -1.132\nEpoch: 5/25 | Batch: 550/636 | Train Loss: 0.1748 | Penalty Loss: 0.0003\neta: 21.020 | lam0: 1.306 | lam1: -1.322\nEpoch: 5/25 | Batch: 600/636 | Train Loss: 0.0400 | Penalty Loss: -0.0040\neta: 21.020 | lam0: 1.599 | lam1: -1.577\nEpoch 5: Validation Accuracy: 0.7892\nEpoch: 6/25 | Batch: 0/636 | Train Loss: 0.0122 | Penalty Loss: 0.0003\neta: 21.230 | lam0: 1.269 | lam1: -1.277\nEpoch: 6/25 | Batch: 50/636 | Train Loss: 0.0729 | Penalty Loss: -0.0039\neta: 21.230 | lam0: 0.803 | lam1: -0.778\nEpoch: 6/25 | Batch: 100/636 | Train Loss: 0.0688 | Penalty Loss: 0.0001\neta: 21.230 | lam0: 0.046 | lam1: -0.046\nEpoch: 6/25 | Batch: 150/636 | Train Loss: 0.0898 | Penalty Loss: 0.0007\neta: 21.230 | lam0: -2.770 | lam1: 2.791\nEpoch: 6/25 | Batch: 200/636 | Train Loss: 0.0343 | Penalty Loss: -0.0019\neta: 21.230 | lam0: -2.808 | lam1: 2.813\nEpoch: 6/25 | Batch: 250/636 | Train Loss: 0.0284 | Penalty Loss: -0.0004\neta: 21.230 | lam0: -1.977 | lam1: 1.973\nEpoch: 6/25 | Batch: 300/636 | Train Loss: 0.0584 | Penalty Loss: 0.0010\neta: 21.230 | lam0: -0.841 | lam1: 0.837\nEpoch: 6/25 | Batch: 350/636 | Train Loss: 0.0402 | Penalty Loss: 0.0008\neta: 21.230 | lam0: -0.021 | lam1: 0.048\nEpoch: 6/25 | Batch: 400/636 | Train Loss: 0.0177 | Penalty Loss: 0.0008\neta: 21.230 | lam0: 1.514 | lam1: -1.523\nEpoch: 6/25 | Batch: 450/636 | Train Loss: 0.0590 | Penalty Loss: 0.0004\neta: 21.230 | lam0: 2.536 | lam1: -2.542\nEpoch: 6/25 | Batch: 500/636 | Train Loss: 0.0236 | Penalty Loss: 0.0044\neta: 21.230 | lam0: 4.178 | lam1: -4.201\nEpoch: 6/25 | Batch: 550/636 | Train Loss: 0.0159 | Penalty Loss: -0.0054\neta: 21.230 | lam0: 5.009 | lam1: -4.979\nEpoch: 6/25 | Batch: 600/636 | Train Loss: 0.0330 | Penalty Loss: -0.0080\neta: 21.230 | lam0: 4.205 | lam1: -4.164\nEpoch 6: Validation Accuracy: 0.7910\nEpoch: 7/25 | Batch: 0/636 | Train Loss: 0.0216 | Penalty Loss: -0.0010\neta: 21.443 | lam0: 4.425 | lam1: -4.419\nEpoch: 7/25 | Batch: 50/636 | Train Loss: 0.0599 | Penalty Loss: -0.0217\neta: 21.443 | lam0: 3.752 | lam1: -3.635\nEpoch: 7/25 | Batch: 100/636 | Train Loss: 0.0220 | Penalty Loss: 0.0001\neta: 21.443 | lam0: 2.969 | lam1: -2.964\nEpoch: 7/25 | Batch: 150/636 | Train Loss: 0.0456 | Penalty Loss: 0.0014\neta: 21.443 | lam0: 2.553 | lam1: -2.564\nEpoch: 7/25 | Batch: 200/636 | Train Loss: 0.0169 | Penalty Loss: 0.0010\neta: 21.443 | lam0: 1.814 | lam1: -1.818\nEpoch: 7/25 | Batch: 250/636 | Train Loss: 0.0292 | Penalty Loss: -0.0039\neta: 21.443 | lam0: 1.316 | lam1: -1.295\nEpoch: 7/25 | Batch: 300/636 | Train Loss: 0.1460 | Penalty Loss: -0.0028\neta: 21.443 | lam0: 0.119 | lam1: -0.104\nEpoch: 7/25 | Batch: 350/636 | Train Loss: 0.0915 | Penalty Loss: 0.0001\neta: 21.443 | lam0: 0.324 | lam1: -0.318\nEpoch: 7/25 | Batch: 400/636 | Train Loss: 0.0292 | Penalty Loss: 0.0005\neta: 21.443 | lam0: 0.225 | lam1: -0.228\nEpoch: 7/25 | Batch: 450/636 | Train Loss: 0.0475 | Penalty Loss: 0.0000\neta: 21.443 | lam0: 1.907 | lam1: -1.904\nEpoch: 7/25 | Batch: 500/636 | Train Loss: 0.0914 | Penalty Loss: -0.0021\neta: 21.443 | lam0: 2.000 | lam1: -2.001\nEpoch: 7/25 | Batch: 550/636 | Train Loss: 0.0355 | Penalty Loss: 0.0007\neta: 21.443 | lam0: 0.937 | lam1: -0.941\nEpoch: 7/25 | Batch: 600/636 | Train Loss: 0.0520 | Penalty Loss: 0.0002\neta: 21.443 | lam0: -0.082 | lam1: 0.080\nEpoch 7: Validation Accuracy: 0.7930\nEpoch: 8/25 | Batch: 0/636 | Train Loss: 0.0053 | Penalty Loss: -0.0009\neta: 21.657 | lam0: 0.473 | lam1: -0.455\nEpoch: 8/25 | Batch: 50/636 | Train Loss: 0.0500 | Penalty Loss: -0.0003\neta: 21.657 | lam0: 1.241 | lam1: -1.246\nEpoch: 8/25 | Batch: 100/636 | Train Loss: 0.0217 | Penalty Loss: 0.0004\neta: 21.657 | lam0: 2.393 | lam1: -2.412\nEpoch: 8/25 | Batch: 150/636 | Train Loss: 0.0286 | Penalty Loss: -0.0068\neta: 21.657 | lam0: 2.039 | lam1: -2.003\nEpoch: 8/25 | Batch: 200/636 | Train Loss: 0.0697 | Penalty Loss: -0.0002\neta: 21.657 | lam0: 1.868 | lam1: -1.867\nEpoch: 8/25 | Batch: 250/636 | Train Loss: 0.0630 | Penalty Loss: 0.0049\neta: 21.657 | lam0: 1.111 | lam1: -1.138\nEpoch: 8/25 | Batch: 300/636 | Train Loss: 0.0354 | Penalty Loss: -0.0000\neta: 21.657 | lam0: 2.850 | lam1: -2.876\nEpoch: 8/25 | Batch: 350/636 | Train Loss: 0.0507 | Penalty Loss: -0.0002\neta: 21.657 | lam0: 3.271 | lam1: -3.273\nEpoch: 8/25 | Batch: 400/636 | Train Loss: 0.0456 | Penalty Loss: -0.0053\neta: 21.657 | lam0: 4.317 | lam1: -4.289\nEpoch: 8/25 | Batch: 450/636 | Train Loss: 0.0173 | Penalty Loss: -0.0014\neta: 21.657 | lam0: 3.994 | lam1: -3.993\nEpoch: 8/25 | Batch: 500/636 | Train Loss: 0.0950 | Penalty Loss: -0.0033\neta: 21.657 | lam0: 2.227 | lam1: -2.208\nEpoch: 8/25 | Batch: 550/636 | Train Loss: 0.0200 | Penalty Loss: 0.0017\neta: 21.657 | lam0: 2.588 | lam1: -2.613\nEpoch: 8/25 | Batch: 600/636 | Train Loss: 0.0572 | Penalty Loss: -0.0048\neta: 21.657 | lam0: 1.423 | lam1: -1.398\nEpoch 8: Validation Accuracy: 0.7931\nEpoch: 9/25 | Batch: 0/636 | Train Loss: 0.0129 | Penalty Loss: -0.0008\neta: 21.874 | lam0: 1.525 | lam1: -1.521\nEpoch: 9/25 | Batch: 50/636 | Train Loss: 0.0307 | Penalty Loss: -0.0064\neta: 21.874 | lam0: 1.198 | lam1: -1.164\nEpoch: 9/25 | Batch: 100/636 | Train Loss: 0.0255 | Penalty Loss: -0.0008\neta: 21.874 | lam0: 1.114 | lam1: -1.134\nEpoch: 9/25 | Batch: 150/636 | Train Loss: 0.0343 | Penalty Loss: 0.0000\neta: 21.874 | lam0: -1.459 | lam1: 1.459\nEpoch: 9/25 | Batch: 200/636 | Train Loss: 0.0131 | Penalty Loss: -0.0001\neta: 21.874 | lam0: 0.106 | lam1: -0.101\nEpoch: 9/25 | Batch: 250/636 | Train Loss: 0.0485 | Penalty Loss: 0.0006\neta: 21.874 | lam0: -0.003 | lam1: -0.008\nEpoch: 9/25 | Batch: 300/636 | Train Loss: 0.1019 | Penalty Loss: -0.0001\neta: 21.874 | lam0: 1.514 | lam1: -1.528\nEpoch: 9/25 | Batch: 350/636 | Train Loss: 0.0141 | Penalty Loss: 0.0007\neta: 21.874 | lam0: 1.415 | lam1: -1.407\nEpoch: 9/25 | Batch: 400/636 | Train Loss: 0.0374 | Penalty Loss: -0.0035\neta: 21.874 | lam0: 2.292 | lam1: -2.273\nEpoch: 9/25 | Batch: 450/636 | Train Loss: 0.0908 | Penalty Loss: -0.0005\neta: 21.874 | lam0: 2.206 | lam1: -2.200\nEpoch: 9/25 | Batch: 500/636 | Train Loss: 0.0254 | Penalty Loss: -0.0002\neta: 21.874 | lam0: 2.464 | lam1: -2.453\nEpoch: 9/25 | Batch: 550/636 | Train Loss: 0.0774 | Penalty Loss: -0.0067\neta: 21.874 | lam0: 4.188 | lam1: -4.130\nEpoch: 9/25 | Batch: 600/636 | Train Loss: 0.0327 | Penalty Loss: -0.0013\neta: 21.874 | lam0: 3.251 | lam1: -3.225\nEpoch 9: Validation Accuracy: 0.7927\nEpoch: 10/25 | Batch: 0/636 | Train Loss: 0.0158 | Penalty Loss: -0.0035\neta: 22.092 | lam0: 1.748 | lam1: -1.728\nEpoch: 10/25 | Batch: 50/636 | Train Loss: 0.0202 | Penalty Loss: -0.0014\neta: 22.092 | lam0: 1.764 | lam1: -1.755\nEpoch: 10/25 | Batch: 100/636 | Train Loss: 0.0329 | Penalty Loss: -0.0002\neta: 22.092 | lam0: 1.396 | lam1: -1.407\nEpoch: 10/25 | Batch: 150/636 | Train Loss: 0.1825 | Penalty Loss: 0.0001\neta: 22.092 | lam0: -0.223 | lam1: 0.222\nEpoch: 10/25 | Batch: 200/636 | Train Loss: 0.0926 | Penalty Loss: 0.0021\neta: 22.092 | lam0: 1.579 | lam1: -1.592\nEpoch: 10/25 | Batch: 250/636 | Train Loss: 0.0220 | Penalty Loss: 0.0101\neta: 22.092 | lam0: 3.366 | lam1: -3.421\nEpoch: 10/25 | Batch: 300/636 | Train Loss: 0.0336 | Penalty Loss: -0.0008\neta: 22.092 | lam0: 2.875 | lam1: -2.870\nEpoch: 10/25 | Batch: 350/636 | Train Loss: 0.0192 | Penalty Loss: -0.0012\neta: 22.092 | lam0: 3.984 | lam1: -3.983\nEpoch: 10/25 | Batch: 400/636 | Train Loss: 0.0698 | Penalty Loss: 0.0252\neta: 22.092 | lam0: 4.423 | lam1: -4.563\nEpoch: 10/25 | Batch: 450/636 | Train Loss: 0.0684 | Penalty Loss: 0.0003\neta: 22.092 | lam0: 2.058 | lam1: -2.055\nEpoch: 10/25 | Batch: 500/636 | Train Loss: 0.0061 | Penalty Loss: -0.0014\neta: 22.092 | lam0: 1.053 | lam1: -1.039\nEpoch: 10/25 | Batch: 550/636 | Train Loss: 0.0483 | Penalty Loss: -0.0000\neta: 22.092 | lam0: 0.470 | lam1: -0.463\nEpoch: 10/25 | Batch: 600/636 | Train Loss: 0.0058 | Penalty Loss: 0.0015\neta: 22.092 | lam0: -0.109 | lam1: 0.077\nEpoch 10: Validation Accuracy: 0.7914\nEpoch: 11/25 | Batch: 0/636 | Train Loss: 0.0059 | Penalty Loss: 0.0014\neta: 22.313 | lam0: -0.276 | lam1: 0.251\nEpoch: 11/25 | Batch: 50/636 | Train Loss: 0.0250 | Penalty Loss: -0.0104\neta: 22.313 | lam0: 0.480 | lam1: -0.422\nEpoch: 11/25 | Batch: 100/636 | Train Loss: 0.0386 | Penalty Loss: -0.0005\neta: 22.313 | lam0: 2.180 | lam1: -2.177\nEpoch: 11/25 | Batch: 150/636 | Train Loss: 0.0549 | Penalty Loss: 0.0023\neta: 22.313 | lam0: 2.391 | lam1: -2.402\nEpoch: 11/25 | Batch: 200/636 | Train Loss: 0.0474 | Penalty Loss: -0.0008\neta: 22.313 | lam0: 3.144 | lam1: -3.156\nEpoch: 11/25 | Batch: 250/636 | Train Loss: 0.0437 | Penalty Loss: -0.0085\neta: 22.313 | lam0: 1.463 | lam1: -1.398\nEpoch: 11/25 | Batch: 300/636 | Train Loss: 0.0462 | Penalty Loss: -0.0001\neta: 22.313 | lam0: 1.732 | lam1: -1.732\nEpoch: 11/25 | Batch: 350/636 | Train Loss: 0.0798 | Penalty Loss: 0.0005\neta: 22.313 | lam0: 0.940 | lam1: -0.944\nEpoch: 11/25 | Batch: 400/636 | Train Loss: 0.0439 | Penalty Loss: 0.0000\neta: 22.313 | lam0: 2.157 | lam1: -2.158\nEpoch: 11/25 | Batch: 450/636 | Train Loss: 0.0728 | Penalty Loss: -0.0000\neta: 22.313 | lam0: 2.436 | lam1: -2.439\nEpoch: 11/25 | Batch: 500/636 | Train Loss: 0.0160 | Penalty Loss: -0.0012\neta: 22.313 | lam0: 2.399 | lam1: -2.392\nEpoch: 11/25 | Batch: 550/636 | Train Loss: 0.0100 | Penalty Loss: -0.0198\neta: 22.313 | lam0: 2.767 | lam1: -2.656\nEpoch: 11/25 | Batch: 600/636 | Train Loss: 0.0152 | Penalty Loss: 0.0053\neta: 22.313 | lam0: 2.416 | lam1: -2.446\nEpoch 11: Validation Accuracy: 0.7920\nEpoch: 12/25 | Batch: 0/636 | Train Loss: 0.0343 | Penalty Loss: 0.0014\neta: 22.537 | lam0: 2.674 | lam1: -2.682\nEpoch: 12/25 | Batch: 50/636 | Train Loss: 0.0404 | Penalty Loss: -0.0000\neta: 22.537 | lam0: 2.799 | lam1: -2.796\nEpoch: 12/25 | Batch: 100/636 | Train Loss: 0.0844 | Penalty Loss: -0.0003\neta: 22.537 | lam0: 2.165 | lam1: -2.166\nEpoch: 12/25 | Batch: 150/636 | Train Loss: 0.0410 | Penalty Loss: 0.0004\neta: 22.537 | lam0: 2.753 | lam1: -2.752\nEpoch: 12/25 | Batch: 200/636 | Train Loss: 0.0959 | Penalty Loss: -0.0001\neta: 22.537 | lam0: 2.715 | lam1: -2.715\nEpoch: 12/25 | Batch: 250/636 | Train Loss: 0.0958 | Penalty Loss: -0.0000\neta: 22.537 | lam0: 2.038 | lam1: -2.038\nEpoch: 12/25 | Batch: 300/636 | Train Loss: 0.0138 | Penalty Loss: 0.0034\neta: 22.537 | lam0: 1.738 | lam1: -1.757\nEpoch: 12/25 | Batch: 350/636 | Train Loss: 0.0519 | Penalty Loss: -0.0007\neta: 22.537 | lam0: 1.678 | lam1: -1.677\nEpoch: 12/25 | Batch: 400/636 | Train Loss: 0.0113 | Penalty Loss: 0.0007\neta: 22.537 | lam0: 2.139 | lam1: -2.147\nEpoch: 12/25 | Batch: 450/636 | Train Loss: 0.0279 | Penalty Loss: -0.0005\neta: 22.537 | lam0: 2.702 | lam1: -2.699\nEpoch: 12/25 | Batch: 500/636 | Train Loss: 0.0265 | Penalty Loss: -0.0001\neta: 22.537 | lam0: 0.990 | lam1: -0.988\nEpoch: 12/25 | Batch: 550/636 | Train Loss: 0.0803 | Penalty Loss: -0.0001\neta: 22.537 | lam0: 0.797 | lam1: -0.796\nEpoch: 12/25 | Batch: 600/636 | Train Loss: 0.0274 | Penalty Loss: -0.0008\neta: 22.537 | lam0: 0.796 | lam1: -0.792\nEpoch 12: Validation Accuracy: 0.7914\nEpoch: 13/25 | Batch: 0/636 | Train Loss: 0.0041 | Penalty Loss: 0.0000\neta: 22.762 | lam0: 0.912 | lam1: -0.912\nEpoch: 13/25 | Batch: 50/636 | Train Loss: 0.0658 | Penalty Loss: 0.0004\neta: 22.762 | lam0: 1.266 | lam1: -1.286\nEpoch: 13/25 | Batch: 100/636 | Train Loss: 0.0599 | Penalty Loss: -0.0008\neta: 22.762 | lam0: 1.223 | lam1: -1.220\nEpoch: 13/25 | Batch: 150/636 | Train Loss: 0.0208 | Penalty Loss: -0.0025\neta: 22.762 | lam0: 2.247 | lam1: -2.237\nEpoch: 13/25 | Batch: 200/636 | Train Loss: 0.0445 | Penalty Loss: -0.0009\neta: 22.762 | lam0: 2.921 | lam1: -2.915\nEpoch: 13/25 | Batch: 250/636 | Train Loss: 0.0630 | Penalty Loss: -0.0005\neta: 22.762 | lam0: 3.424 | lam1: -3.436\nEpoch: 13/25 | Batch: 300/636 | Train Loss: 0.0382 | Penalty Loss: -0.0000\neta: 22.762 | lam0: 4.597 | lam1: -4.598\nEpoch: 13/25 | Batch: 350/636 | Train Loss: 0.0112 | Penalty Loss: -0.0006\neta: 22.762 | lam0: 4.401 | lam1: -4.388\nEpoch: 13/25 | Batch: 400/636 | Train Loss: 0.0548 | Penalty Loss: 0.0017\neta: 22.762 | lam0: 2.830 | lam1: -2.831\nEpoch: 13/25 | Batch: 450/636 | Train Loss: 0.0045 | Penalty Loss: 0.0022\neta: 22.762 | lam0: 2.284 | lam1: -2.293\nEpoch: 13/25 | Batch: 500/636 | Train Loss: 0.0253 | Penalty Loss: 0.0008\neta: 22.762 | lam0: 2.159 | lam1: -2.159\nEpoch: 13/25 | Batch: 550/636 | Train Loss: 0.0203 | Penalty Loss: -0.0001\neta: 22.762 | lam0: 2.428 | lam1: -2.428\nEpoch: 13/25 | Batch: 600/636 | Train Loss: 0.0226 | Penalty Loss: -0.0067\neta: 22.762 | lam0: 1.773 | lam1: -1.735\nEpoch 13: Validation Accuracy: 0.7924\nNo improvement for 5 epochs. Early stopping...\nTraining completed in 3253.90 seconds.\n","output_type":"stream"}],"execution_count":99},{"cell_type":"code","source":"def test_model(model_in_fn, test_loader, gpu_yes = True):\n    model_in_fn.eval()  # Set model to evaluation mode\n    if gpu_yes:\n        device = 'cuda'\n        model_in_fn.to(device)\n    else:\n        device='cpu'\n        model_in_fn.to('cpu')\n    # Initialize counters\n    correct, total = 0, 0\n    male_correct, female_correct = 0, 0\n    male_total, female_total = 0, 0\n    \n    # Initialize confusion matrix components for males and females\n    male_tp, male_fp, male_tn, male_fn = 0, 0, 0, 0\n    female_tp, female_fp, female_tn, female_fn = 0, 0, 0, 0\n    all_ones, all_zeros = 0, 0\n    \n    with torch.no_grad():\n        for images, labels, genders in test_loader:\n            images, labels, genders = images.to(device), labels.to(device), genders.to(device)\n            outputs = model_in_fn(images)\n            _, predicted = torch.max(outputs, 1)\n            \n            # Update overall accuracy\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n            \n            # Count total positive and negative cases\n            all_ones += (labels == 1).sum().item()\n            all_zeros += (labels == 0).sum().item()\n            \n            # Separate male and female predictions\n            male_mask = (genders == 1)\n            female_mask = (genders == 0)\n            \n            # Update accuracy counts\n            male_correct += (predicted[male_mask] == labels[male_mask]).sum().item()\n            female_correct += (predicted[female_mask] == labels[female_mask]).sum().item()\n            male_total += male_mask.sum().item()\n            female_total += female_mask.sum().item()\n            \n            # Update confusion matrix components for males\n            male_tp += ((predicted[male_mask] == 1) & (labels[male_mask] == 1)).sum().item()\n            male_fp += ((predicted[male_mask] == 1) & (labels[male_mask] == 0)).sum().item()\n            male_tn += ((predicted[male_mask] == 0) & (labels[male_mask] == 0)).sum().item()\n            male_fn += ((predicted[male_mask] == 0) & (labels[male_mask] == 1)).sum().item()\n            \n            # Update confusion matrix components for females\n            female_tp += ((predicted[female_mask] == 1) & (labels[female_mask] == 1)).sum().item()\n            female_fp += ((predicted[female_mask] == 1) & (labels[female_mask] == 0)).sum().item()\n            female_tn += ((predicted[female_mask] == 0) & (labels[female_mask] == 0)).sum().item()\n            female_fn += ((predicted[female_mask] == 0) & (labels[female_mask] == 1)).sum().item()\n    \n    # Calculate metrics\n    overall_accuracy = correct / total\n    male_accuracy = male_correct / male_total if male_total > 0 else 0\n    female_accuracy = female_correct / female_total if female_total > 0 else 0\n    \n    # Calculate TPR and FPR correctly\n    male_tpr = male_tp / (male_tp + male_fn) if (male_tp + male_fn) > 0 else 0\n    female_tpr = female_tp / (female_tp + female_fn) if (female_tp + female_fn) > 0 else 0\n    male_fpr = male_fp / (male_fp + male_tn) if (male_fp + male_tn) > 0 else 0\n    female_fpr = female_fp / (female_fp + female_tn) if (female_fp + female_tn) > 0 else 0\n    \n    # Fairness metrics\n    DEO = abs(male_tpr - female_tpr)\n    FPR_diff = abs(male_fpr - female_fpr)\n    \n    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n    print(f\"Male Accuracy: {male_accuracy:.4f}\")\n    print(f\"Female Accuracy: {female_accuracy:.2f}\")\n    print(f\"Male TPR: {male_tpr:.2f}\")\n    print(f\"Female TPR: {female_tpr:.2f}\")\n    print(f\"Male FPR: {male_fpr:.2f}\")\n    print(f\"Female FPR: {female_fpr:.2f}\")\n    print(f\"Demographic Equal Opportunity (DEO): {DEO:.2f}\")\n    print(f\"False Positive Rate Difference (FPR): {FPR_diff:.2f}\")\n    \n    return {\n        \"overall_accuracy\": overall_accuracy,\n        \"male_accuracy\": male_accuracy,\n        \"female_accuracy\": female_accuracy,\n        \"male_tpr\": male_tpr,\n        \"female_tpr\": female_tpr,\n        \"male_fpr\": male_fpr,\n        \"female_fpr\": female_fpr,\n        \"DEO\": DEO,\n        \"FPR_difference\": FPR_diff,\n        \"Attractive yes in test\": all_ones/total,\n        \"Attractive no in test\": all_zeros/total,\n        \"Batch Size\": BATCH_SIZE\n    }, model_in_fn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T09:52:47.886565Z","iopub.execute_input":"2024-11-18T09:52:47.886982Z","iopub.status.idle":"2024-11-18T09:52:47.910223Z","shell.execute_reply.started":"2024-11-18T09:52:47.886943Z","shell.execute_reply":"2024-11-18T09:52:47.909172Z"}},"outputs":[],"execution_count":119},{"cell_type":"code","source":"test_model(model,test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T09:52:55.306321Z","iopub.execute_input":"2024-11-18T09:52:55.306704Z","iopub.status.idle":"2024-11-18T09:53:12.441243Z","shell.execute_reply.started":"2024-11-18T09:52:55.306667Z","shell.execute_reply":"2024-11-18T09:53:12.440114Z"}},"outputs":[{"name":"stdout","text":"Overall Accuracy: 0.7962\nMale Accuracy: 0.7983\nFemale Accuracy: 0.79\nMale TPR: 0.74\nFemale TPR: 0.92\nMale FPR: 0.18\nFemale FPR: 0.43\nDemographic Equal Opportunity (DEO): 0.18\nFalse Positive Rate Difference (FPR): 0.25\n","output_type":"stream"},{"execution_count":120,"output_type":"execute_result","data":{"text/plain":"({'overall_accuracy': 0.7962128043282236,\n  'male_accuracy': 0.7983149708360338,\n  'female_accuracy': 0.7948885441332572,\n  'male_tpr': 0.7366771159874608,\n  'female_tpr': 0.9154559118236473,\n  'male_fpr': 0.18134804344078606,\n  'female_fpr': 0.4309171944639925,\n  'DEO': 0.1787787958361865,\n  'FPR_difference': 0.24956915102320645,\n  'Attractive yes in test': 0.49584209998998097,\n  'Attractive no in test': 0.504157900010019,\n  'Batch Size': 256},\n DataParallel(\n   (module): ResNet(\n     (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (relu): ReLU(inplace=True)\n     (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n     (layer1): Sequential(\n       (0): BasicBlock(\n         (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n         (relu): ReLU(inplace=True)\n         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n       (1): BasicBlock(\n         (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n         (relu): ReLU(inplace=True)\n         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (layer2): Sequential(\n       (0): BasicBlock(\n         (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n         (relu): ReLU(inplace=True)\n         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n         (downsample): Sequential(\n           (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n           (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n         )\n       )\n       (1): BasicBlock(\n         (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n         (relu): ReLU(inplace=True)\n         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (layer3): Sequential(\n       (0): BasicBlock(\n         (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n         (relu): ReLU(inplace=True)\n         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n         (downsample): Sequential(\n           (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n           (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n         )\n       )\n       (1): BasicBlock(\n         (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n         (relu): ReLU(inplace=True)\n         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (layer4): Sequential(\n       (0): BasicBlock(\n         (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n         (relu): ReLU(inplace=True)\n         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n         (downsample): Sequential(\n           (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n           (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n         )\n       )\n       (1): BasicBlock(\n         (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n         (relu): ReLU(inplace=True)\n         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n     (fc): Linear(in_features=512, out_features=2, bias=True)\n   )\n ))"},"metadata":{}}],"execution_count":120},{"cell_type":"code","source":"torch.save(model, \"/kaggle/working/fairALM_finetuned_celebA\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T09:54:56.889773Z","iopub.execute_input":"2024-11-18T09:54:56.890220Z","iopub.status.idle":"2024-11-18T09:54:56.990410Z","shell.execute_reply.started":"2024-11-18T09:54:56.890175Z","shell.execute_reply":"2024-11-18T09:54:56.989610Z"}},"outputs":[],"execution_count":121},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"def get_res_dict():\n    res = {'acc': None,\n           'ddp': None,\n           'ppv': None,\n           'fpr': None,\n           'fnr': None,\n           'tn_s0': None,\n           'tn_s1': None,\n           'fp_s0': None,\n           'fp_s1': None,\n           'fn_s0': None,\n           'fn_s1': None,\n           'tp_s0': None,\n           'tp_s1': None\n    }\n    return res","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:49:37.768667Z","iopub.execute_input":"2024-11-18T09:49:37.769599Z","iopub.status.idle":"2024-11-18T09:49:37.779430Z","shell.execute_reply.started":"2024-11-18T09:49:37.769548Z","shell.execute_reply":"2024-11-18T09:49:37.778431Z"},"trusted":true},"outputs":[],"execution_count":103},{"cell_type":"code","source":"def compute_accuracy(config, model, data_loader):\n    correct_pred, num_examples = 0, 0\n\n    num_protected0, num_protected1 = 0, 0\n    num_correct_pred_protected0, num_correct_pred_protected1 = 0, 0\n\n    num_pred1_protected0, num_pred1_protected1 = 0, 0\n    num_targets0_protected0, num_targets0_protected1 = 0, 0\n    num_targets1_protected0, num_targets1_protected1 = 0, 0\n    \n    num_pred0_targets0_protected0, num_pred0_targets0_protected1 = 0, 0\n    num_pred1_targets0_protected0, num_pred1_targets0_protected1 = 0, 0\n    num_pred0_targets1_protected0, num_pred0_targets1_protected1 = 0, 0\n    num_pred1_targets1_protected0, num_pred1_targets1_protected1 = 0, 0\n\n    for i, (features, targets, protected) in enumerate(data_loader):\n        if config['DEBUG'] and i > 1:\n            break\n        features = features.cuda()\n        targets = targets.cuda()\n        protected = protected.cuda()\n#         logits, probas = model(features)\n        \n        preprocess = transforms.Compose([\n                    transforms.Resize((224, 224)),  # Resizing to 224x224\n                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n                ])\n\n                # Apply preprocessing to each image in the batch\n        input_tensor = torch.stack([preprocess(image) for image in features])\n\n                # Forward pass to get logits\n        logits = model(input_tensor)\n        probas = torch.nn.functional.softmax(logits, dim=1)\n        _, predicted_labels = torch.max(probas, 1)\n        num_examples += 1.*targets.size(0) \n        correct_pred += (predicted_labels == targets).float().sum() # CHANGED\n\n        # For DDP metric\n        num_protected0 += (protected == 0).float().sum()\n        num_protected1 += (protected == 1).float().sum()\n        num_correct_pred_protected0 += ((predicted_labels == targets) & (protected == 0)).float().sum()\n        num_correct_pred_protected1 += ((predicted_labels == targets) & (protected == 1)).float().sum()\n\n        # For PPV metric\n        num_pred1_protected0 += ((predicted_labels == 1) & (protected == 0)).float().sum()\n        num_pred1_protected1 += ((predicted_labels == 1) & (protected == 1)).float().sum()\n        \n        # For FPR metric\n        num_targets0_protected0 += ((targets == 0) & (protected == 0)).float().sum()\n        num_targets0_protected1 += ((targets == 0) & (protected == 1)).float().sum()\n        \n        # For FNR metric\n        num_targets1_protected0 += ((targets == 1) & (protected == 0)).float().sum()\n        num_targets1_protected1 += ((targets == 1) & (protected == 1)).float().sum()\n\n        num_pred0_targets0_protected0 += ((predicted_labels == 0) & (targets == 0) & (protected == 0)).float().sum()\n        num_pred0_targets0_protected1 += ((predicted_labels == 0) & (targets == 0) & (protected == 1)).float().sum()\n        num_pred1_targets0_protected0 += ((predicted_labels == 1) & (targets == 0) & (protected == 0)).float().sum()\n        num_pred1_targets0_protected1 += ((predicted_labels == 1) & (targets == 0) & (protected == 1)).float().sum()\n        num_pred0_targets1_protected0 += ((predicted_labels == 0) & (targets == 1) & (protected == 0)).float().sum()\n        num_pred0_targets1_protected1 += ((predicted_labels == 0) & (targets == 1) & (protected == 1)).float().sum()\n        num_pred1_targets1_protected0 += ((predicted_labels == 1) & (targets == 1) & (protected == 0)).float().sum()\n        num_pred1_targets1_protected1 += ((predicted_labels == 1) & (targets == 1) & (protected == 1)).float().sum()\n\n    # res imported from utils\n    res = get_res_dict()\n\n    res['acc'] = correct_pred.float()/num_examples * 100\n\n    res['ddp'] = abs(num_correct_pred_protected0 / (num_protected0 + 1e-6) - num_correct_pred_protected1 / (num_protected1 + 1e-6)) * 100\n\n    res['ppv'] = abs(num_pred1_targets1_protected0 / (num_pred1_protected0 + 1e-6) - num_pred1_targets1_protected1 / (num_pred1_protected1 + 1e-6)) * 100\n\n    res['fpr'] = abs(num_pred0_targets0_protected0 / (num_targets0_protected0 + 1e-6) - num_pred0_targets0_protected1 / (num_targets0_protected1 + 1e-6)) * 100\n\n    res['fnr'] = abs(num_pred1_targets1_protected0 / (num_targets1_protected0 + 1e-6) - num_pred1_targets1_protected1 / (num_targets1_protected1 + 1e-6)) * 100\n\n    res['tn_s0'] = num_pred0_targets0_protected0\n    res['tn_s1'] = num_pred0_targets0_protected1\n    res['fp_s0'] = num_pred1_targets0_protected0\n    res['fp_s1'] = num_pred1_targets0_protected1\n    res['fn_s0'] = num_pred0_targets1_protected0\n    res['fn_s1'] = num_pred0_targets1_protected1\n    res['tp_s0'] = num_pred1_targets1_protected0\n    res['tp_s1'] = num_pred1_targets1_protected1\n    \n    return res","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:49:37.781304Z","iopub.execute_input":"2024-11-18T09:49:37.781922Z","iopub.status.idle":"2024-11-18T09:49:37.806363Z","shell.execute_reply.started":"2024-11-18T09:49:37.781863Z","shell.execute_reply":"2024-11-18T09:49:37.805370Z"},"trusted":true},"outputs":[],"execution_count":104},{"cell_type":"code","source":"def print_stats(config, epoch, stats, stat_type='Train'):\n    if stat_type == 'Train':\n        print('Epoch: %03d/%03d | Train Acc: %.3f%% | Train Ddp: %.3f%% | Train Ppv: %.3f%% | Train Fpr: %.3f%% | Train Fnr: %.3f%% ' % (\n            epoch+1, config['NUM_EPOCHS'], \n            stats['acc'],\n            stats['ddp'],\n            stats['ppv'],\n            stats['fpr'],\n            stats['fnr']))\n        print('                 | Train TP0: %d | Train FP0: %d | Train FN0: %d | Train TP0: %d' % (\n            stats['tn_s0'],\n            stats['fp_s0'],\n            stats['fn_s0'],\n            stats['tp_s0']))\n        print('                 | Train TP1: %d | Train FP1: %d | Train FN1: %d | Train TP1: %d' % (\n            stats['tn_s1'],\n            stats['fp_s1'],\n            stats['fn_s1'],\n            stats['tp_s1']))\n    elif stat_type == 'Valid' and not config['DEBUG']:\n        print('Epoch: %03d/%03d | Valid Acc: %.3f%% | Valid Ddp: %.3f%% | Valid Ppv: %.3f%% | Valid Fpr: %.3f%% | Valid Fnr: %.3f%% ' % (\n            epoch+1, config['NUM_EPOCHS'], \n            stats['acc'],\n            stats['ddp'],\n            stats['ppv'],\n            stats['fpr'],\n            stats['fnr']))\n        print('                 | Valid TP0: %d | Valid FP0: %d | Valid FN0: %d | Valid TP0: %d' % (\n            stats['tn_s0'],\n            stats['fp_s0'],\n            stats['fn_s0'],\n            stats['tp_s0']))\n        print('                 | Valid TP1: %d | Valid FP1: %d | Valid FN1: %d | Valid TP1: %d' % (\n            stats['tn_s1'],\n            stats['fp_s1'],\n            stats['fn_s1'],\n            stats['tp_s1']))\n    elif stat_type == 'Test' and not config['DEBUG']:\n        print('Epoch: %03d/%03d | Test Acc: %.3f%% | Test Ddp: %.3f%% | Test Ppv: %.3f%% | Test Fpr: %.3f%% | Test Fnr: %.3f%% ' % (\n            epoch+1, config['NUM_EPOCHS'], \n            stats['acc'],\n            stats['ddp'],\n            stats['ppv'],\n            stats['fpr'],\n            stats['fnr']))\n        print('                 | Test TP0: %d | Test FP0: %d | Test FN0: %d | Test TP0: %d' % (\n            stats['tn_s0'],\n            stats['fp_s0'],\n            stats['fn_s0'],\n            stats['tp_s0']))\n        print('                 | Test TP1: %d | Test FP1: %d | Test FN1: %d | Test TP1: %d' % (\n            stats['tn_s1'],\n            stats['fp_s1'],\n            stats['fn_s1'],\n            stats['tp_s1']))","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:49:37.807816Z","iopub.execute_input":"2024-11-18T09:49:37.808197Z","iopub.status.idle":"2024-11-18T09:49:37.819986Z","shell.execute_reply.started":"2024-11-18T09:49:37.808156Z","shell.execute_reply":"2024-11-18T09:49:37.819109Z"},"trusted":true},"outputs":[],"execution_count":105},{"cell_type":"code","source":"print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))\nwith torch.set_grad_enabled(False): # save memory during inference\n    test_stats = compute_accuracy(config, model, test_loader)\n    print_stats(config, epoch, test_stats, stat_type='Test')","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:49:37.821091Z","iopub.execute_input":"2024-11-18T09:49:37.821420Z","iopub.status.idle":"2024-11-18T09:49:57.945381Z","shell.execute_reply.started":"2024-11-18T09:49:37.821389Z","shell.execute_reply":"2024-11-18T09:49:57.944220Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Total Training Time: 55.04 min\nEpoch: 013/025 | Test Acc: 55.170% | Test Ddp: 31.852% | Test Ppv: 34.445% | Test Fpr: 1.894% | Test Fnr: 2.511% \n                 | Test TP0: 3964 | Test FP0: 299 | Test FN0: 6699 | Test TP0: 1285\n                 | Test TP1: 5504 | Test FP1: 297 | Test FN1: 1654 | Test TP1: 260\n","output_type":"stream"}],"execution_count":106},{"cell_type":"markdown","source":"The training log you provided seems to be related to a binary classification problem with metrics often used to assess both performance and fairness of a model. Let’s break down each component:\n\n1. **Epoch**:  \n   - `Epoch: 030/030` indicates that training has completed 30 out of 30 epochs.\n\n2. **Test Accuracy (`Test Acc`)**:  \n   - `Test Acc: 49.594%` refers to the overall accuracy of the model on the test set, meaning that approximately 49.59% of the test predictions were correct.\n\n3. **Test Disparate Impact (`Test Ddp`)**:  \n   - `Test Ddp: 40.357%` could represent a fairness metric, possibly indicating disparate impact or demographic disparity. It measures how different groups are treated in terms of positive predictions. A value closer to 100% would indicate less disparity.\n\n4. **Test Positive Predictive Value (`Test Ppv`)**:  \n   - `Test Ppv: 40.376%` indicates the precision, which is the proportion of true positive predictions out of all positive predictions. It measures how many predicted positives are actually positive.\n\n5. **Test False Positive Rate (`Test Fpr`)**:  \n   - `Test Fpr: 0.034%` shows the proportion of negatives that were incorrectly classified as positives. It's very low, indicating very few false positives relative to the total number of actual negatives.\n\n6. **Test False Negative Rate (`Test Fnr`)**:  \n   - `Test Fnr: 0.000%` indicates no false negatives, meaning all actual positive cases were correctly identified by the model.\n\n7. **Confusion Matrix Breakdown**:  \n   - `Test TP0: 7984`, `Test FP0: 4263`, `Test FN0: 0`, `Test TP1: 1914`, `Test FP1: 5799`, `Test FN1: 0`\n   - These metrics provide the true positives (TP), false positives (FP), and false negatives (FN) for both classes (0 and 1):\n     - `TP0` and `TP1`: True positives for class 0 and class 1, respectively.\n     - `FP0` and `FP1`: False positives for class 0 and class 1.\n     - `FN0` and `FN1`: False negatives for class 0 and class 1 (both are zero here).\n\nGiven that this is based on a fairness-oriented loss function, it seems like the metrics are aimed at evaluating not just the performance but also how well the model balances errors across different groups or classes. The fairness measures (like `Test Ddp`) are likely used to ensure that the model's predictions are equitable across groups. \n\nThe results show a challenge in achieving high accuracy, indicating the model might still need tuning, especially in terms of improving both accuracy and fairness metrics simultaneously.","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/working/model_weights_30epochs.pth')","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:49:57.947168Z","iopub.execute_input":"2024-11-18T09:49:57.948094Z","iopub.status.idle":"2024-11-18T09:49:58.027045Z","shell.execute_reply.started":"2024-11-18T09:49:57.948042Z","shell.execute_reply":"2024-11-18T09:49:58.026245Z"},"trusted":true},"outputs":[],"execution_count":107},{"cell_type":"markdown","source":"# Testing and compression","metadata":{}},{"cell_type":"code","source":"import torchvision.models as models\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:49:58.028249Z","iopub.execute_input":"2024-11-18T09:49:58.028590Z","iopub.status.idle":"2024-11-18T09:49:58.033030Z","shell.execute_reply.started":"2024-11-18T09:49:58.028555Z","shell.execute_reply":"2024-11-18T09:49:58.031866Z"},"trusted":true},"outputs":[],"execution_count":108},{"cell_type":"code","source":"\n\n# Define your custom ResNet18 model\nclass CustomResNet18(nn.Module):\n    def __init__(self, num_classes):\n        super(CustomResNet18, self).__init__()\n        self.base_model = models.resnet18(pretrained=False)  # No pretrained weights\n        self.base_model.fc = nn.Linear(self.base_model.fc.in_features, num_classes)  # Modify last layer\n\n    def forward(self, x):\n        return self.base_model(x)\n\n# Initialize your custom model\nnum_classes = 2  # Replace with the number of classes in your dataset\nmodel_download = CustomResNet18(num_classes)\n\n# Load your custom weights\ncustom_weights_path = \"/kaggle/input/resnet18_celeba_finetuned_pre_compression_/pytorch/default/1/model_weights_30epochs.pth\"\n\n# Load state_dict and handle missing or unexpected keys\nstate_dict = torch.load(custom_weights_path)\nmodel_download.load_state_dict(state_dict, strict=False)  # Use strict=False to ignore mismatches\n\n# Optionally, set the model to evaluation mode if you're using it for inference\nmodel_download.eval()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:49:58.034152Z","iopub.execute_input":"2024-11-18T09:49:58.034507Z","iopub.status.idle":"2024-11-18T09:49:58.767277Z","shell.execute_reply.started":"2024-11-18T09:49:58.034475Z","shell.execute_reply":"2024-11-18T09:49:58.766303Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n/tmp/ipykernel_30/3622632210.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load(custom_weights_path)\n","output_type":"stream"},{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"CustomResNet18(\n  (base_model): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=512, out_features=2, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":109},{"cell_type":"code","source":"def model_size_evaluator(model_size_karo):\n    num_params = sum(p.numel() for p in model_size_karo.parameters())\n    size_mb = num_params * 4 / (1024 * 1024)  # assuming 4-byte floats\n    print(f\"Size of the model: {size_mb:.2f} MB\")","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:49:58.774683Z","iopub.execute_input":"2024-11-18T09:49:58.774995Z","iopub.status.idle":"2024-11-18T09:49:58.782232Z","shell.execute_reply.started":"2024-11-18T09:49:58.774964Z","shell.execute_reply":"2024-11-18T09:49:58.781302Z"},"trusted":true},"outputs":[],"execution_count":110},{"cell_type":"code","source":"model_size_evaluator(model_download)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:49:58.783387Z","iopub.execute_input":"2024-11-18T09:49:58.783740Z","iopub.status.idle":"2024-11-18T09:49:58.788913Z","shell.execute_reply.started":"2024-11-18T09:49:58.783700Z","shell.execute_reply":"2024-11-18T09:49:58.788014Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Size of the model: 42.64 MB\n","output_type":"stream"}],"execution_count":111},{"cell_type":"markdown","source":"# Experiments - Pruning followed by testing\n\n\n\r\n**Pruning**\r\n\r\n* Identify prunable parameters:\r\n\t+ Random: Prune random parameters.\r\n\t+ Magnitude: Prune parameters with smallest weights (L2 norm).\r\n\t+ Gradient: Prune based on accumulated gradient (requires backward pass).\r\n\t+ Information: Use high-order curvature information.\r\n\t+ Learned: Train network to prune itself (expensive).\r\n* PyTorch supports random and magnitude-based pruning, which are effective and easy to compute.o compute.ny data.","metadata":{}},{"cell_type":"markdown","source":"![](https://miro.medium.com/v2/resize:fit:786/format:webp/1*l7Nx7TtTSHdqISSzbNrtiA.png)","metadata":{}},{"cell_type":"markdown","source":"Types of pruning - \n**Unstructured Pruning** \n\nUnstructured Puning refers to pruning individual atoms of parameters. E.g. individual weights in linear layers, individual filter pixels in convolution layers, some scaling floats in your custom layer, etc. The point is you prune parameters without their respective structure, hence the name unstructured pruning. - \n\n**Structured Pruning** \nAs an alternative to unstructured pruning, structured pruning removes entire structures of parameters. This does not mean that it has to be an entire parameter, but you go beyond removing individual atoms e.g. in linear weights you’d drop entire rows or columns, or, in convolution layers entire filters (I point the interested reader to [1] where we have shown that many publicly available models contain a bunch of degenerated filters that should be prunable). In practice, you can achieve much higher pruning ratios with unstructured pruning, but it probably won’t speed up your model, as you still have to do all computations. Structured pruning can e.g. prune entire convolution channels and therefore significantly lower the number of matrix multiplications you need. Currently, there is a trend to support sparse tensors in both soft- and hardware, so in the future unstructured pruning may become highly relevant. \n\n**- Local vs. Global Pruning:** Pruning can happen per layer (local) or over all multiple/all layers (global). (global).","metadata":{}},{"cell_type":"code","source":"import torch.nn.utils.prune as prune","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:49:58.789998Z","iopub.execute_input":"2024-11-18T09:49:58.790361Z","iopub.status.idle":"2024-11-18T09:49:58.799058Z","shell.execute_reply.started":"2024-11-18T09:49:58.790306Z","shell.execute_reply":"2024-11-18T09:49:58.798202Z"},"trusted":true},"outputs":[],"execution_count":112},{"cell_type":"code","source":"def test_function_forall(m, compute_accuracy = compute_accuracy, config=config, test_loader=test_loader):\n    with torch.set_grad_enabled(False): # save memory during inference\n        test_stats = compute_accuracy(config, m, test_loader)\n        print_stats(config, 30, test_stats, stat_type='Test') #putting epoch as 0","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:49:58.799983Z","iopub.execute_input":"2024-11-18T09:49:58.800295Z","iopub.status.idle":"2024-11-18T09:49:58.805471Z","shell.execute_reply.started":"2024-11-18T09:49:58.800265Z","shell.execute_reply":"2024-11-18T09:49:58.804471Z"},"trusted":true},"outputs":[],"execution_count":113},{"cell_type":"code","source":"model_download.cuda()\ntest_function_forall(model_download)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:49:58.806493Z","iopub.execute_input":"2024-11-18T09:49:58.806774Z","iopub.status.idle":"2024-11-18T09:50:23.750910Z","shell.execute_reply.started":"2024-11-18T09:49:58.806744Z","shell.execute_reply":"2024-11-18T09:50:23.749810Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch: 031/025 | Test Acc: 50.416% | Test Ddp: 40.383% | Test Ppv: 0.000% | Test Fpr: 0.000% | Test Fnr: 0.000% \n                 | Test TP0: 4263 | Test FP0: 0 | Test FN0: 7984 | Test TP0: 0\n                 | Test TP1: 5801 | Test FP1: 0 | Test FN1: 1914 | Test TP1: 0\n","output_type":"stream"}],"execution_count":114},{"cell_type":"code","source":"# Helper function to recursively add parameters to prune\ndef add_pruning_params(model, params_to_prune):\n    for module in model.children():\n        if isinstance(module, (nn.Conv2d, nn.Linear)):\n            params_to_prune.append((module, 'weight'))\n        else:\n            # Recurse only if the module is not an atomic layer\n            # This will correctly handle nested structures like nn.Sequential\n            add_pruning_params(module, params_to_prune)\n\n# Function to count the number of zero weights in a model\ndef count_zero_weights(model):\n    num_zeros = 0\n    num_total = 0\n    for module in model.modules():\n        if isinstance(module, (nn.Conv2d, nn.Linear)):\n            num_zeros += torch.sum(module.weight == 0).item()\n            num_total += module.weight.numel()\n    return num_zeros, num_total\n\n# 1. Global Structured Pruning (pruning entire channels across all layers)\ndef global_structured_pruning(model, amount=0.3):\n    parameters_to_prune = []\n    add_pruning_params(model, parameters_to_prune)\n    prune.global_unstructured(parameters_to_prune, pruning_method=prune.LnStructured, amount=amount, n=2)\n    return model\n\n# 2. Global Unstructured Pruning (pruning individual weights across all layers)\ndef global_unstructured_pruning(model, amount=0.3):\n    parameters_to_prune = []\n    add_pruning_params(model, parameters_to_prune)\n    prune.global_unstructured(parameters_to_prune, pruning_method=prune.L1Unstructured, amount=amount)\n    return model\n\n# 3. Local Structured Pruning (pruning channels in specific layers)\ndef local_structured_pruning(model, amount=0.5):\n    for name, module in model.named_modules():\n        if isinstance(module, (nn.Conv2d, nn.Linear)):\n            prune.ln_structured(module, name='weight', amount=amount, n=2, dim=0)\n            prune.remove(module, 'weight')  # Apply the mask\n    return model\n\n# 4. Local Unstructured Pruning (pruning individual weights in specific layers)\ndef local_unstructured_pruning(model, amount=0.5):\n    for name, module in model.named_modules():\n        if isinstance(module, (nn.Conv2d, nn.Linear)):\n            prune.l1_unstructured(module, name='weight', amount=amount)\n            prune.remove(module, 'weight')  # Apply the mask\n    return model\n\n# # Apply each pruning technique and check results\n# print(\"Applying Global Structured Pruning...\")\n# model_global_structured = global_structured_pruning(model, amount=0.3)\n# num_zeros, num_total = count_zero_weights(model_global_structured)\n# print(f\"Global Structured Pruning: {num_zeros}/{num_total} weights are zero\")\n\n# print(\"Applying Global Unstructured Pruning...\")\n# model_global_unstructured = global_unstructured_pruning(model_download, amount=0.3)\n# num_zeros, num_total = count_zero_weights(model_global_unstructured)\n# print(f\"Global Unstructured Pruning: {num_zeros}/{num_total} weights are zero\")\n\n# print(\"Applying Local Structured Pruning...\")\n# model_local_structured = local_structured_pruning(model_download, amount=0.5)\n# num_zeros, num_total = count_zero_weights(model_local_structured)\n# print(f\"Local Structured Pruning: {num_zeros}/{num_total} weights are zero\")\n\n# print(\"Applying Local Unstructured Pruning...\")\n# model_local_unstructured = local_unstructured_pruning(model_download, amount=0.5)\n# num_zeros, num_total = count_zero_weights(model_local_unstructured)\n# print(f\"Local Unstructured Pruning: {num_zeros}/{num_total} weights are zero\")","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:50:23.752951Z","iopub.execute_input":"2024-11-18T09:50:23.753762Z","iopub.status.idle":"2024-11-18T09:50:23.767523Z","shell.execute_reply.started":"2024-11-18T09:50:23.753710Z","shell.execute_reply":"2024-11-18T09:50:23.766608Z"},"trusted":true},"outputs":[],"execution_count":115},{"cell_type":"code","source":"import copy\n\n# def test_function_forall(m, compute_accuracy, config, test_loader):\n#     m.eval()  # Make sure the model is in evaluation mode\n#     with torch.set_grad_enabled(False):  # Disable gradient calculations\n#         test_stats = compute_accuracy(config, m, test_loader)\n#         print_stats(config, 30, test_stats, stat_type='Test')  # Use 30 as the epoch (dummy value here)\n\n# def test_function_forall(m, compute_accuracy = compute_accuracy, config=config, test_loader=test_loader):\n#     with torch.set_grad_enabled(False): # save memory during inference\n#         test_stats = compute_accuracy(config, m, test_loader)\n#         print_stats(config, 30, test_stats, stat_type='Test') #putting epoch as 0\n\ndef prune_and_test_model(original_model, pruning_method, amount):\n    # Step 1: Clone the original model to avoid modifying the original model\n    pruned_model = copy.deepcopy(original_model)\n    pruned_model.cuda()\n    \n    # Step 2: Apply the specified pruning method\n    if pruning_method == 'global_structured':\n        pruned_model = global_structured_pruning(pruned_model, amount)\n    elif pruning_method == 'global_unstructured':\n        pruned_model = global_unstructured_pruning(pruned_model, amount)\n    elif pruning_method == 'local_structured':\n        pruned_model = local_structured_pruning(pruned_model, amount)\n    elif pruning_method == 'local_unstructured':\n        pruned_model = local_unstructured_pruning(pruned_model, amount)\n    else:\n        raise ValueError(\"Invalid pruning method specified\")\n\n    # Step 3: Test the pruned model\n    print(f\"Testing {pruning_method} pruning...\")\n    model_size_evaluator(pruned_model)\n    test_function_forall(m=pruned_model, compute_accuracy=compute_accuracy, config=config, test_loader=test_loader)\n\n    # Step 4: Optionally, count the number of zero weights to verify pruning\n    num_zeros, num_total = count_zero_weights(pruned_model)\n    print(f\"{pruning_method} Pruning: {num_zeros}/{num_total} weights are zero\")\n\n# Example usage for different pruning methods\n# print(\"Testing Global Structured Pruning...\")\n# prune_and_test_model(model_download, 'global_structured', 0.3)\n\n# print(\"Testing Global Unstructured Pruning...\")\n# prune_and_test_model(model_download, 'global_unstructured', 0.9)\n\n# print(\"Testing Local Structured Pruning...\")\n# prune_and_test_model(model_download, 'local_structured', 0.5)\n\n# print(\"Testing Local Unstructured Pruning...\")\n# prune_and_test_model(model_download, 'local_unstructured', 0.5)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:50:23.769005Z","iopub.execute_input":"2024-11-18T09:50:23.769397Z","iopub.status.idle":"2024-11-18T09:50:23.784862Z","shell.execute_reply.started":"2024-11-18T09:50:23.769354Z","shell.execute_reply":"2024-11-18T09:50:23.783925Z"},"trusted":true},"outputs":[],"execution_count":116},{"cell_type":"code","source":"def iterator_pruner(model, method):\n    print(f\"Testing {method}...\\n\")\n    for i in range(1,11,1):\n        # copy_model = copy.deepcopy(model)\n        sparsity_number = i/10\n        print(f\"The sparsity is => {sparsity_number}\")\n        prune_and_test_model(model, method, sparsity_number)\n        print()\n    print(\"\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:50:23.785865Z","iopub.execute_input":"2024-11-18T09:50:23.786163Z","iopub.status.idle":"2024-11-18T09:50:23.797069Z","shell.execute_reply.started":"2024-11-18T09:50:23.786132Z","shell.execute_reply":"2024-11-18T09:50:23.796213Z"},"trusted":true},"outputs":[],"execution_count":117},{"cell_type":"code","source":"iterator_pruner(model_download, \"global_unstructured\")","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:50:23.798038Z","iopub.execute_input":"2024-11-18T09:50:23.798301Z","iopub.status.idle":"2024-11-18T09:52:30.547240Z","shell.execute_reply.started":"2024-11-18T09:50:23.798271Z","shell.execute_reply":"2024-11-18T09:52:30.544519Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Testing global_unstructured...\n\nThe sparsity is => 0.1\nTesting global_unstructured pruning...\nSize of the model: 42.64 MB\nEpoch: 031/025 | Test Acc: 50.416% | Test Ddp: 40.383% | Test Ppv: 0.000% | Test Fpr: 0.000% | Test Fnr: 0.000% \n                 | Test TP0: 4263 | Test FP0: 0 | Test FN0: 7984 | Test TP0: 0\n                 | Test TP1: 5801 | Test FP1: 0 | Test FN1: 1914 | Test TP1: 0\nglobal_unstructured Pruning: 1116794/11167936 weights are zero\n\nThe sparsity is => 0.2\nTesting global_unstructured pruning...\nSize of the model: 42.64 MB\nEpoch: 031/025 | Test Acc: 50.416% | Test Ddp: 40.383% | Test Ppv: 0.000% | Test Fpr: 0.000% | Test Fnr: 0.000% \n                 | Test TP0: 4263 | Test FP0: 0 | Test FN0: 7984 | Test TP0: 0\n                 | Test TP1: 5801 | Test FP1: 0 | Test FN1: 1914 | Test TP1: 0\nglobal_unstructured Pruning: 2233587/11167936 weights are zero\n\nThe sparsity is => 0.3\nTesting global_unstructured pruning...\nSize of the model: 42.64 MB\nEpoch: 031/025 | Test Acc: 50.416% | Test Ddp: 40.383% | Test Ppv: 0.000% | Test Fpr: 0.000% | Test Fnr: 0.000% \n                 | Test TP0: 4263 | Test FP0: 0 | Test FN0: 7984 | Test TP0: 0\n                 | Test TP1: 5801 | Test FP1: 0 | Test FN1: 1914 | Test TP1: 0\nglobal_unstructured Pruning: 3350381/11167936 weights are zero\n\nThe sparsity is => 0.4\nTesting global_unstructured pruning...\nSize of the model: 42.64 MB\nEpoch: 031/025 | Test Acc: 50.416% | Test Ddp: 40.383% | Test Ppv: 0.000% | Test Fpr: 0.000% | Test Fnr: 0.000% \n                 | Test TP0: 4263 | Test FP0: 0 | Test FN0: 7984 | Test TP0: 0\n                 | Test TP1: 5801 | Test FP1: 0 | Test FN1: 1914 | Test TP1: 0\nglobal_unstructured Pruning: 4467174/11167936 weights are zero\n\nThe sparsity is => 0.5\nTesting global_unstructured pruning...\nSize of the model: 42.64 MB\nEpoch: 031/025 | Test Acc: 50.416% | Test Ddp: 40.383% | Test Ppv: 0.000% | Test Fpr: 0.000% | Test Fnr: 0.000% \n                 | Test TP0: 4263 | Test FP0: 0 | Test FN0: 7984 | Test TP0: 0\n                 | Test TP1: 5801 | Test FP1: 0 | Test FN1: 1914 | Test TP1: 0\nglobal_unstructured Pruning: 5583968/11167936 weights are zero\n\nThe sparsity is => 0.6\nTesting global_unstructured pruning...\nSize of the model: 42.64 MB\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[118], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43miterator_pruner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mglobal_unstructured\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[117], line 7\u001b[0m, in \u001b[0;36miterator_pruner\u001b[0;34m(model, method)\u001b[0m\n\u001b[1;32m      5\u001b[0m     sparsity_number \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe sparsity is => \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msparsity_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mprune_and_test_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparsity_number\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[116], line 34\u001b[0m, in \u001b[0;36mprune_and_test_model\u001b[0;34m(original_model, pruning_method, amount)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpruning_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m pruning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m model_size_evaluator(pruned_model)\n\u001b[0;32m---> 34\u001b[0m \u001b[43mtest_function_forall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpruned_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_accuracy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_accuracy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Step 4: Optionally, count the number of zero weights to verify pruning\u001b[39;00m\n\u001b[1;32m     37\u001b[0m num_zeros, num_total \u001b[38;5;241m=\u001b[39m count_zero_weights(pruned_model)\n","Cell \u001b[0;32mIn[113], line 3\u001b[0m, in \u001b[0;36mtest_function_forall\u001b[0;34m(m, compute_accuracy, config, test_loader)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_function_forall\u001b[39m(m, compute_accuracy \u001b[38;5;241m=\u001b[39m compute_accuracy, config\u001b[38;5;241m=\u001b[39mconfig, test_loader\u001b[38;5;241m=\u001b[39mtest_loader):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m): \u001b[38;5;66;03m# save memory during inference\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m         test_stats \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m         print_stats(config, \u001b[38;5;241m30\u001b[39m, test_stats, stat_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[0;32mIn[104], line 17\u001b[0m, in \u001b[0;36mcompute_accuracy\u001b[0;34m(config, model, data_loader)\u001b[0m\n\u001b[1;32m     14\u001b[0m num_pred1_targets1_protected0, num_pred1_targets1_protected1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (features, targets, protected) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEBUG\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mcuda()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":118},{"cell_type":"code","source":"iterator_pruner(model_download, \"local_structured\")","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:52:30.548370Z","iopub.status.idle":"2024-11-18T09:52:30.548780Z","shell.execute_reply.started":"2024-11-18T09:52:30.548586Z","shell.execute_reply":"2024-11-18T09:52:30.548606Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"iterator_pruner(model_download, \"local_unstructured\")","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:52:30.550264Z","iopub.status.idle":"2024-11-18T09:52:30.550642Z","shell.execute_reply.started":"2024-11-18T09:52:30.550457Z","shell.execute_reply":"2024-11-18T09:52:30.550475Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def count_zero_weights(model):\n    num_zeros = 0\n    num_total = 0\n    for param in model.parameters():\n        if param is not None:\n            num_zeros += torch.sum(param == 0).item()\n            num_total += param.numel()\n    return num_zeros, num_total\n\n# Before pruning\nnum_zeros_before, num_total_before = count_zero_weights(model_download)\nprint(f\"Before Pruning: {num_zeros_before}/{num_total_before} weights are zero\")\n\npruned_model = copy.deepcopy(model_download)\npruned_model = global_unstructured_pruning(pruned_model, 0.2)\n\n# After pruning\nnum_zeros_after, num_total_after = count_zero_weights(pruned_model)\nprint(f\"After Pruning: {num_zeros_after}/{num_total_after} weights are zero\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T09:52:30.552383Z","iopub.status.idle":"2024-11-18T09:52:30.552853Z","shell.execute_reply.started":"2024-11-18T09:52:30.552606Z","shell.execute_reply":"2024-11-18T09:52:30.552631Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The provided code demonstrates different pruning techniques for a neural network model, which involve selectively removing some weights or entire structures (such as channels) to reduce the model’s size, potentially speed up inference, and mitigate overfitting while maintaining accuracy. Let’s explore these techniques and how they are implemented in code.\r\n\r\n### Conceptual Overview of Pruning\r\n\r\n1. **What is Pruning?**\r\n   - Pruning is a model optimization technique used to eliminate unnecessary or less significant parameters (weights or structures) from a neural network. The goal is to simplify the model without significantly affecting its performance, which can result in a more compact model with faster inference times and lower memory usage.\r\n\r\n2. **Types of Pruning in the Code:**\r\n   - **Global Unstructured Pruning:** Removes individual weights across all layers based on a specified criterion, such as L1-norm, without considering the structure of the layers.\r\n   - **Local Structured Pruning:** Eliminates entire structures, like channels or filters, within specific layers. This retains the network's architecture but reduces the number of computations per layer.\r\n   - **Local Unstructured Pruning:** Prunes individual weights within specific layers, treating each layer independently and pruning based on some criteria (e.g., L1-norm).\r\n\r\n### Code Explanation\r\n\r\n#### 1. **Helper Function – `add_pruning_params`**\r\n\r\n   - **Purpose:** This function traverses through the model's layers and adds the parameters that need to be pruned (in this case, weights of `nn.Conv2d` and `nn.Linear` layers) to a list.\r\n   - **Implementation Details:**\r\n     - It iterates over each module in the model using `model.children()`.\r\n     - If a module is an instance of `nn.Conv2d` or `nn.Linear`, it appends a tuple containing the module and the string `'weight'` to the `params_to_prune` list. This tells the pruning methods that the weights of these layers should be considered for pruning.\r\n     - If the module is not an atomic layer (like `nn.Sequential`), the function recursively calls itself to explore nested structures.\r\n\r\n#### 2. **Global Unstructured Pruning – `global_unstructured_pruning`**\r\n\r\n   - **Purpose:** Prunes a fraction of weights across all layers based on their importance, without considering the structure. The importance is determined using the L1 norm of the weights.\r\n   - **Implementation Details:**\r\n     - `parameters_to_prune` is initialized as an empty list.\r\n     - The `add_pruning_params` function is called to populate `parameters_to_prune` with all the weights that can be pruned.\r\n     - The `prune.global_unstructured` function applies pruning globally across the listed parameters, with `prune.L1Unstructured` as the pruning criterion. This method ranks the weights based on their L1 norm (absolute values) and removes the specified proportion (`amount=0.3` in this case).\r\n     - The function returns the pruned model.\r\n\r\n#### 3. **Local Structured Pruning – `local_structured_pruning`**\r\n\r\n   - **Purpose:** Prunes entire structures, such as channels in convolutional layers or rows in linear layers. This retains the overall structure but reduces the layer's computational burden.\r\n   - **Implementation Details:**\r\n     - It iterates over each named module in the model using `model.named_modules()`.\r\n     - If a module is an `nn.Conv2d` or `nn.Linear` layer, it applies `prune.ln_structured` to prune channels (or rows) based on the L2 norm (`n=2`). The `dim=0` argument specifies that the pruning is along the channel dimension (filters in Conv2D).\r\n     - After pruning, `prune.remove` is called to finalize the pruning mask, updating the module's weight parameters accordingly. This step essentially removes the \"pruning hooks\" and makes the changes permanent.\r\n     - The function returns the pruned model.\r\n\r\n#### 4. **Local Unstructured Pruning – `local_unstructured_pruning`**\r\n\r\n   - **Purpose:** Prunes individual weights within specific layers without considering the global distribution of weights.\r\n   - **Implementation Details:**\r\n     - Similar to local structured pruning, this function iterates over each named module.\r\n     - For each `nn.Conv2d` or `nn.Linear` module, it applies `prune.l1_unstructured`, which prunes weights with the smallest absolute values (based on the L1 norm), retaining a specified percentage (`amount=0.5`).\r\n     - `prune.remove` is used to finalize and apply the pruning, making the changes permanent.\r\n     - The function then returns the modified model.\r\n\r\n### How the Code Achieves Pruning\r\n\r\n- **Parameter Selection:** The code identifies which weights or structures are eligible for pruning (using `add_pruning_params` and conditions for layer types).\r\n- **Pruning Methods:**\r\n  - `prune.global_unstructured` performs pruning across all eligible weights based on a global criterion.\r\n  - `prune.ln_structured` and `prune.l1_unstructured` prune weights locally within individual layers, either by removing whole channels or individual weights.\r\n- **Mask Application:** During pruning, masks are applied to the weights to zero out the pruned elements. These masks can be removed using `prune.remove`, which updates the model's parameters.\r\n\r\nEach function essentially defines different pruning strategies, allowing flexibility in optimizing models based on various criteria. Do you need any specific part of the code or concept clarified further?","metadata":{}},{"cell_type":"markdown","source":"Sure! Let's simplify the explanation for **structured pruning**:\r\n\r\n### What is Structured Pruning?\r\n\r\n- Structured pruning removes entire \"blocks\" or \"structures\" within a layer, such as:\r\n  - **Channels** in convolutional layers (like removing entire filters).\r\n  - **Neurons** or **rows** in fully connected layers.\r\n- Unlike unstructured pruning, which prunes individual weights, structured pruning prunes whole groups of weights together, effectively shrinking the layer's size.\r\n\r\n### Meaning of `amount` in Structured Pruning\r\n\r\n- In structured pruning, `amount` represents the **fraction of the structure** (e.g., channels in a convolutional layer) to prune.\r\n- For example, if `amount=0.5`, it means **50% of the channels** in that layer will be removed.\r\n- The code decides which channels to prune based on their importance, often measured by some norm (like L2 norm). Less important channels (those with smaller norm values) get pruned.\r\n\r\n### Example for Clarity\r\n\r\nImagine a convolutional layer has **8 channels (filters)**:\r\n- If `amount=0.5`, structured pruning will remove **4 of these channels**, effectively reducing the layer from 8 channels to 4.\r\n- This makes the layer more compact and can speed up computations because fewer channels mean fewer operations.\r\n\r\nIn short, structured pruning shrinks layers by removing entire channels or neurons, and the `amount` specifies what percentage of them to prune away.","metadata":{}},{"cell_type":"markdown","source":"Great question! The reason we typically don’t use **structured global pruning** boils down to a few practical challenges and limitations:\r\n\r\n### 1. **Complexity of Comparing Structures Across Different Layers**\r\n   - In structured pruning, we are removing entire structures like channels (filters) or neurons, which are inherently different across layers. For example, comparing a channel in a convolutional layer to a row in a fully connected layer isn't straightforward because they have different shapes, functions, and impacts on the model.\r\n   - Structured global pruning would require a way to rank and compare these different structures across all layers in a unified manner, which is much more complex than comparing individual weights.\r\n\r\n### 2. **Maintaining Model Architecture Consistency**\r\n   - Pruning entire channels or neurons affects the dimensionality of the input and output of layers. In structured local pruning, we can handle this within individual layers because we know how the inputs/outputs should change.\r\n   - If we prune structures globally across layers, we may end up affecting connections between layers in unpredictable ways, potentially breaking the architecture or requiring significant re-engineering to adjust the dimensions.\r\n\r\n### 3. **Layer-specific Importance**\r\n   - Different layers in a neural network have different levels of importance. Early layers often capture basic features (e.g., edges in images), while deeper layers capture higher-level abstractions (e.g., objects).\r\n   - Removing an entire structure (like a filter) from a deeper layer might have a more significant impact on performance compared to a shallow layer. Local pruning allows for layer-specific pruning criteria, ensuring that each layer is pruned in a way that accounts for its role in the network.\r\n\r\n### In Contrast: Why Global Unstructured Pruning Works\r\n- **Global unstructured pruning** works by comparing individual weights across all layers, which is simpler because every weight is a single scalar value. We can rank and prune these values regardless of their layer, making it suitable for global pruning.\r\n\r\n### Summary\r\nWe don’t do **structured global pruning** because it’s difficult to compare and prune entire structures across different layers in a meaningful way while maintaining the model’s architecture. Local structured pruning is preferred since it allows for targeted pruning within specific layers, preserving the network's overall structure and functionality.","metadata":{}}]}