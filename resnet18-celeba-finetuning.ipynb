{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":37705,"sourceType":"datasetVersion","datasetId":29561},{"sourceId":150643,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":127922,"modelId":150847}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-17T18:49:51.923582Z","iopub.execute_input":"2024-11-17T18:49:51.924042Z","iopub.status.idle":"2024-11-17T18:49:51.929604Z","shell.execute_reply.started":"2024-11-17T18:49:51.924003Z","shell.execute_reply":"2024-11-17T18:49:51.928703Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"print(\"hello world\")","metadata":{"execution":{"iopub.status.busy":"2024-11-17T20:44:02.108335Z","iopub.execute_input":"2024-11-17T20:44:02.109022Z","iopub.status.idle":"2024-11-17T20:44:02.114106Z","shell.execute_reply.started":"2024-11-17T20:44:02.108983Z","shell.execute_reply":"2024-11-17T20:44:02.112917Z"},"trusted":true},"outputs":[{"name":"stdout","text":"hello world\n","output_type":"stream"}],"execution_count":38},{"cell_type":"markdown","source":"# libs","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\n\nimport timm\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport sys\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-11-17T18:49:51.944946Z","iopub.execute_input":"2024-11-17T18:49:51.945274Z","iopub.status.idle":"2024-11-17T18:49:58.090743Z","shell.execute_reply.started":"2024-11-17T18:49:51.945243Z","shell.execute_reply":"2024-11-17T18:49:58.089987Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from PIL import Image  # Importing the Image module\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-11-17T18:49:58.091719Z","iopub.execute_input":"2024-11-17T18:49:58.092160Z","iopub.status.idle":"2024-11-17T18:49:58.096306Z","shell.execute_reply.started":"2024-11-17T18:49:58.092127Z","shell.execute_reply":"2024-11-17T18:49:58.095429Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# hyper-param","metadata":{}},{"cell_type":"code","source":"##########################\n### SETTINGS\n##########################\n\n# Hyperparameters\nRANDOM_SEED = 1\n\n# Dynamically set device\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {DEVICE}\")\n\nGRAYSCALE = False","metadata":{"execution":{"iopub.status.busy":"2024-11-17T18:49:58.099126Z","iopub.execute_input":"2024-11-17T18:49:58.099462Z","iopub.status.idle":"2024-11-17T18:49:58.130043Z","shell.execute_reply.started":"2024-11-17T18:49:58.099430Z","shell.execute_reply":"2024-11-17T18:49:58.128792Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"train_size = int(10000*.8)\nvalidation_size = int(10000*.1)\ntest_size = int(10000*.1)","metadata":{"execution":{"iopub.status.busy":"2024-11-17T18:49:58.131291Z","iopub.execute_input":"2024-11-17T18:49:58.131581Z","iopub.status.idle":"2024-11-17T18:49:58.141511Z","shell.execute_reply.started":"2024-11-17T18:49:58.131550Z","shell.execute_reply":"2024-11-17T18:49:58.140743Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### model development and fine-tuning","metadata":{}},{"cell_type":"code","source":"import torchvision.models as models\n\n# Load the pre-trained ResNet-18 model\n# model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\nmodel = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)","metadata":{"execution":{"iopub.status.busy":"2024-11-17T18:49:58.142594Z","iopub.execute_input":"2024-11-17T18:49:58.142922Z","iopub.status.idle":"2024-11-17T18:49:58.814027Z","shell.execute_reply.started":"2024-11-17T18:49:58.142883Z","shell.execute_reply":"2024-11-17T18:49:58.813212Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 175MB/s] \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Freeze all the pre-trained layers\nfor param in model.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2024-11-17T18:49:58.815377Z","iopub.execute_input":"2024-11-17T18:49:58.816026Z","iopub.status.idle":"2024-11-17T18:49:58.820192Z","shell.execute_reply.started":"2024-11-17T18:49:58.815991Z","shell.execute_reply":"2024-11-17T18:49:58.819205Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Modify the last layer of the model\nnum_classes = 2 # replace with the number of classes in your dataset\nmodel.fc = torch.nn.Linear(model.fc.in_features, num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-11-17T18:49:58.821308Z","iopub.execute_input":"2024-11-17T18:49:58.822062Z","iopub.status.idle":"2024-11-17T18:49:58.831574Z","shell.execute_reply.started":"2024-11-17T18:49:58.822014Z","shell.execute_reply":"2024-11-17T18:49:58.830745Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"for param in model.fc.parameters():\n    param.requires_grad = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T18:49:58.832621Z","iopub.execute_input":"2024-11-17T18:49:58.832938Z","iopub.status.idle":"2024-11-17T18:49:58.844798Z","shell.execute_reply.started":"2024-11-17T18:49:58.832891Z","shell.execute_reply":"2024-11-17T18:49:58.843928Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### loading dataset ","metadata":{}},{"cell_type":"code","source":"\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nfrom torchvision import datasets\nfrom torchvision import transforms","metadata":{"execution":{"iopub.status.busy":"2024-11-17T18:49:58.849687Z","iopub.execute_input":"2024-11-17T18:49:58.849996Z","iopub.status.idle":"2024-11-17T18:49:58.854744Z","shell.execute_reply.started":"2024-11-17T18:49:58.849962Z","shell.execute_reply":"2024-11-17T18:49:58.853781Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"#The target label is attractiveness and protected attribute is gender.\n\ndata_root = \"/kaggle/input/celeba-dataset/\"\nlabel_attr = \"Attractive\"\nprotected_attr = \"Male\"","metadata":{"execution":{"iopub.status.busy":"2024-11-17T18:49:58.855846Z","iopub.execute_input":"2024-11-17T18:49:58.856163Z","iopub.status.idle":"2024-11-17T18:49:58.865478Z","shell.execute_reply.started":"2024-11-17T18:49:58.856132Z","shell.execute_reply":"2024-11-17T18:49:58.864411Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class CelebaDataset(Dataset):\n    \n    def __init__(self, csv_path, img_dir, transform=None, label_attr = 'Attractive', protected_attr = 'Male'):\n        \n        df = pd.read_csv(csv_path, index_col=0)\n        self.img_dir = img_dir\n        self.csv_path = csv_path\n        self.img_names = df.index.values\n        self.y = df[label_attr].values\n        self.p = df[protected_attr].values\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        img = Image.open(os.path.join(self.img_dir,\n                      self.img_names[index]))\n\n        if self.transform is not None:\n            img = self.transform(img)\n            \n        label = self.y[index]\n        protected = self.p[index]\n        return img, label, protected\n        \n    def __len__(self):\n        return self.y.shape[0]\n","metadata":{"execution":{"iopub.status.busy":"2024-11-17T18:49:58.866640Z","iopub.execute_input":"2024-11-17T18:49:58.866955Z","iopub.status.idle":"2024-11-17T18:49:58.877072Z","shell.execute_reply.started":"2024-11-17T18:49:58.866921Z","shell.execute_reply":"2024-11-17T18:49:58.876282Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"other_data_root = '/kaggle/working/' #for writing purposes","metadata":{"execution":{"iopub.status.busy":"2024-11-17T18:49:58.878059Z","iopub.execute_input":"2024-11-17T18:49:58.878352Z","iopub.status.idle":"2024-11-17T18:49:58.887145Z","shell.execute_reply.started":"2024-11-17T18:49:58.878319Z","shell.execute_reply":"2024-11-17T18:49:58.886263Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"BATCH_SIZE=1500","metadata":{"execution":{"iopub.status.busy":"2024-11-17T18:49:58.888197Z","iopub.execute_input":"2024-11-17T18:49:58.888484Z","iopub.status.idle":"2024-11-17T18:49:58.897546Z","shell.execute_reply.started":"2024-11-17T18:49:58.888451Z","shell.execute_reply":"2024-11-17T18:49:58.896678Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def prepare_dataset(label_attr = 'Attractive', protected_attr = 'Male'):\n\n    print('Using label attribute:', label_attr)\n\n    df1 = pd.read_csv(data_root + 'list_attr_celeba.csv',usecols=[label_attr, protected_attr])\n    # Make 0 (female) & 1 (male) labels instead of -1 & 1\n    df1.loc[df1[label_attr] == -1, label_attr] = 0\n    df1.loc[df1[protected_attr] == -1, protected_attr] = 0\n    \n#     print(f\"df1\\n{df1}\")\n\n    df2 = pd.read_csv(data_root + 'list_eval_partition.csv')\n    df2.columns = ['image_id', 'partition']\n    image_series = df2['image_id']\n    df2 = df2.set_index('image_id')\n#     print(f\"df2\\n{df2}\")\n\n#     print(\"\\n\\n\")\n#     print(f\"df2 shape {df2.shape} and df1 shape {df1.shape}\")\n\n    df1 = df1.set_index(image_series)\n\n#     df3 = df1.merge(df2, left_index=True, right_index=True)\n    df3 = pd.concat([df1,df2],axis=1)\n#     print(\"\\n\\n\\n\\n\")\n#     print(df1.index)  \n#     print(df2.index)\n#     print(\"\\n\\n\\n\\n\")\n    \n#     print(f\"alt df3 \\n{ df1.merge(df2, left_index=True, right_index=True)}\")\n#     print(f\"df3\\n{df3}\")\n\n    \n    \n    \n    df3.to_csv(other_data_root + 'celeba-attractive-partitions.csv')\n#     print(df3)\n#     print(pd.read_csv(new_data_root+'celeba-attractive-partitions.csv'))\n    df4 = pd.read_csv(other_data_root + 'celeba-attractive-partitions.csv', index_col=0)\n\n    df4.loc[df4['partition'] == 0].to_csv(other_data_root + 'celeba-attractive-train.csv')\n    df4.loc[df4['partition'] == 1].to_csv(other_data_root + 'celeba-attractive-valid.csv')\n    df4.loc[df4['partition'] == 2].to_csv(other_data_root + 'celeba-attractive-test.csv')\n    \n#     print(f\"Train samples: {df4.loc[df4['partition'] == 0].shape[0]}\")\n#     print(f\"Valid samples: {df4.loc[df4['partition'] == 1].shape[0]}\")\n#     print(f\"Test samples: {df4.loc[df4['partition'] == 2].shape[0]}\")\n\n    \ndef get_loaders():\n\n    prepare_dataset(label_attr, protected_attr)\n    \n    # Note that transforms.ToTensor()\n    # already divides pixels by 255. internally\n\n    custom_transform = transforms.Compose([transforms.CenterCrop((178, 178)),\n                                           transforms.Resize((128, 128)),\n                                           transforms.ToTensor()])\n\n    train_dataset = CelebaDataset(csv_path=other_data_root + 'celeba-attractive-train.csv',\n                                  img_dir=data_root + 'img_align_celeba/img_align_celeba',\n                                  transform=custom_transform,\n                                  label_attr=label_attr,\n                                  protected_attr = protected_attr)\n\n    valid_dataset = CelebaDataset(csv_path=other_data_root + 'celeba-attractive-valid.csv',\n                                  img_dir=data_root + 'img_align_celeba/img_align_celeba',\n                                  transform=custom_transform,\n                                  label_attr=label_attr,\n                                  protected_attr = protected_attr)\n\n    test_dataset = CelebaDataset(csv_path=other_data_root + 'celeba-attractive-test.csv',\n                                 img_dir=data_root + 'img_align_celeba/img_align_celeba',\n                                 transform=custom_transform,\n                                 label_attr=label_attr,\n                                 protected_attr = protected_attr)\n\n    train_loader = DataLoader(dataset=train_dataset,\n                              batch_size=BATCH_SIZE,\n                              shuffle=True,\n                              num_workers=4)\n\n    valid_loader = DataLoader(dataset=valid_dataset,\n                              batch_size=BATCH_SIZE,\n                              shuffle=False,\n                              num_workers=4)\n    \n    test_loader = DataLoader(dataset=test_dataset,\n                             batch_size=BATCH_SIZE,\n                             shuffle=False,\n                             num_workers=4)\n\n    return train_loader, valid_loader, test_loader\n","metadata":{"execution":{"iopub.status.busy":"2024-11-17T18:49:58.898653Z","iopub.execute_input":"2024-11-17T18:49:58.898998Z","iopub.status.idle":"2024-11-17T18:49:58.914933Z","shell.execute_reply.started":"2024-11-17T18:49:58.898967Z","shell.execute_reply":"2024-11-17T18:49:58.914115Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"train_loader, valid_loader, test_loader = get_loaders()","metadata":{"execution":{"iopub.status.busy":"2024-11-17T18:49:58.916081Z","iopub.execute_input":"2024-11-17T18:49:58.916375Z","iopub.status.idle":"2024-11-17T18:50:00.849831Z","shell.execute_reply.started":"2024-11-17T18:49:58.916325Z","shell.execute_reply":"2024-11-17T18:50:00.849011Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Using label attribute: Attractive\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# for i in rangetest_loader:","metadata":{"execution":{"iopub.status.busy":"2024-11-17T18:50:00.851214Z","iopub.execute_input":"2024-11-17T18:50:00.851499Z","iopub.status.idle":"2024-11-17T18:50:00.855213Z","shell.execute_reply.started":"2024-11-17T18:50:00.851469Z","shell.execute_reply":"2024-11-17T18:50:00.854304Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2024-11-17T18:50:00.856365Z","iopub.execute_input":"2024-11-17T18:50:00.856677Z","iopub.status.idle":"2024-11-17T18:50:00.865972Z","shell.execute_reply.started":"2024-11-17T18:50:00.856630Z","shell.execute_reply":"2024-11-17T18:50:00.865179Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.cuda.amp import autocast, GradScaler\nimport time","metadata":{"execution":{"iopub.status.busy":"2024-11-17T18:50:00.867201Z","iopub.execute_input":"2024-11-17T18:50:00.867614Z","iopub.status.idle":"2024-11-17T18:50:00.875287Z","shell.execute_reply.started":"2024-11-17T18:50:00.867553Z","shell.execute_reply":"2024-11-17T18:50:00.874444Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Define the criterion, optimizer, and other parameters\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001)\nscaler = GradScaler()  # For mixed precision training\n\nnum_epochs = 25\nvalidate_every = 2\npatience = 3  # Number of epochs to wait before early stopping\nbest_valid_loss = float('inf')\nno_improve_epochs = 0\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\nprint(\"heu\")","metadata":{"execution":{"iopub.status.busy":"2024-11-17T18:50:00.876375Z","iopub.execute_input":"2024-11-17T18:50:00.876776Z","iopub.status.idle":"2024-11-17T18:50:01.045575Z","shell.execute_reply.started":"2024-11-17T18:50:00.876727Z","shell.execute_reply":"2024-11-17T18:50:01.044625Z"},"trusted":true},"outputs":[{"name":"stdout","text":"heu\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/309015131.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()  # For mixed precision training\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Training and validation loop\nfor epoch in range(num_epochs):\n    start_time = time.time()  # Track time at the start of each epoch\n    model.train()  # Set model to training mode\n    running_loss = 0.0  # Reset cumulative training loss for this epoch\n\n    print(f\"Epoch {epoch + 1}/{num_epochs}: Starting training...\")\n    for batch_idx, (images, labels, _) in enumerate(train_loader):  # Loop through training batches\n        images, labels = images.to(device), labels.to(device)  # Move data to the selected device\n        optimizer.zero_grad()  # Clear gradients from the previous step\n\n        # Forward pass with mixed precision for efficiency\n        with autocast():\n            outputs = model(images)  # Get predictions from the model\n            loss = criterion(outputs, labels)  # Calculate the loss\n\n        # Backward pass and optimization step\n        scaler.scale(loss).backward()  # Scale the loss for mixed precision\n        scaler.step(optimizer)  # Update model weights\n        scaler.update()  # Update the scaler for mixed precision\n\n        running_loss += loss.item()  # Accumulate training loss\n\n        # Optional: Log batch-level progress\n        if (batch_idx + 1) % (len(train_loader) // 5) == 0:  # Log 5 times per epoch\n            print(f\"  Batch [{batch_idx + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n\n    # Calculate average training loss for the epoch\n    avg_train_loss = running_loss / len(train_loader)\n    epoch_time = time.time() - start_time  # Calculate epoch duration\n    print(f\"Epoch [{epoch + 1}/{num_epochs}] Complete. Train Loss: {avg_train_loss:.4f}, Time: {epoch_time:.2f}s\")\n\n    # Validation step (only every `validate_every` epochs)\n    if (epoch + 1) % validate_every == 0:\n        print(f\"Epoch {epoch + 1}: Starting validation...\")\n        model.eval()  # Set model to evaluation mode\n        valid_loss = 0.0  # Reset cumulative validation loss\n        correct = 0  # Count of correct predictions\n        total = 0  # Total number of samples\n\n        with torch.no_grad():  # No gradients needed during validation\n            for images, labels, _ in valid_loader:  # Loop through validation batches\n                images, labels = images.to(device), labels.to(device)  # Move data to the selected device\n\n                outputs = model(images)  # Get predictions\n                loss = criterion(outputs, labels)  # Calculate the loss\n                valid_loss += loss.item()  # Accumulate validation loss\n\n                # Calculate accuracy\n                _, predicted = torch.max(outputs, 1)  # Get predicted class\n                total += labels.size(0)  # Update total sample count\n                correct += (predicted == labels).sum().item()  # Update correct prediction count\n\n        # Calculate validation loss and accuracy\n        avg_valid_loss = valid_loss / len(valid_loader)\n        accuracy = 100 * correct / total\n        print(f\"Validation Results - Loss: {avg_valid_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n\n        # Early stopping logic\n        if avg_valid_loss < best_valid_loss:\n            best_valid_loss = avg_valid_loss  # Update the best validation loss\n            no_improve_epochs = 0  # Reset patience counter\n            print(\"  Validation loss improved. Resetting early stopping counter.\")\n        else:\n            no_improve_epochs += 1  # Increment patience counter\n            print(f\"  No improvement in validation loss. Patience: {no_improve_epochs}/{patience}\")\n            if no_improve_epochs >= patience:\n                print(\"Early stopping triggered. Stopping training.\")\n                break  # Exit the training loop\n    ","metadata":{"execution":{"iopub.status.busy":"2024-11-17T18:50:01.046790Z","iopub.execute_input":"2024-11-17T18:50:01.047074Z","iopub.status.idle":"2024-11-17T19:56:07.072217Z","shell.execute_reply.started":"2024-11-17T18:50:01.047044Z","shell.execute_reply":"2024-11-17T19:56:07.070935Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/25: Starting training...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/70649097.py:13: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n","output_type":"stream"},{"name":"stdout","text":"  Batch [21/109], Loss: 0.7499\n  Batch [42/109], Loss: 0.7051\n  Batch [63/109], Loss: 0.6557\n  Batch [84/109], Loss: 0.6319\n  Batch [105/109], Loss: 0.6174\nEpoch [1/25] Complete. Train Loss: 0.6776, Time: 360.62s\nEpoch 2/25: Starting training...\n  Batch [21/109], Loss: 0.6003\n  Batch [42/109], Loss: 0.5612\n  Batch [63/109], Loss: 0.5489\n  Batch [84/109], Loss: 0.5515\n  Batch [105/109], Loss: 0.5315\nEpoch [2/25] Complete. Train Loss: 0.5669, Time: 137.13s\nEpoch 2: Starting validation...\nValidation Results - Loss: 0.5596, Accuracy: 71.61%\n  Validation loss improved. Resetting early stopping counter.\nEpoch 3/25: Starting training...\n  Batch [21/109], Loss: 0.5263\n  Batch [42/109], Loss: 0.5231\n  Batch [63/109], Loss: 0.5329\n  Batch [84/109], Loss: 0.5307\n  Batch [105/109], Loss: 0.5132\nEpoch [3/25] Complete. Train Loss: 0.5324, Time: 138.25s\nEpoch 4/25: Starting training...\n  Batch [21/109], Loss: 0.5255\n  Batch [42/109], Loss: 0.5127\n  Batch [63/109], Loss: 0.5163\n  Batch [84/109], Loss: 0.4932\n  Batch [105/109], Loss: 0.5146\nEpoch [4/25] Complete. Train Loss: 0.5175, Time: 143.10s\nEpoch 4: Starting validation...\nValidation Results - Loss: 0.5271, Accuracy: 74.08%\n  Validation loss improved. Resetting early stopping counter.\nEpoch 5/25: Starting training...\n  Batch [21/109], Loss: 0.5142\n  Batch [42/109], Loss: 0.5331\n  Batch [63/109], Loss: 0.4777\n  Batch [84/109], Loss: 0.4943\n  Batch [105/109], Loss: 0.5058\nEpoch [5/25] Complete. Train Loss: 0.5089, Time: 142.16s\nEpoch 6/25: Starting training...\n  Batch [21/109], Loss: 0.5140\n  Batch [42/109], Loss: 0.5115\n  Batch [63/109], Loss: 0.4645\n  Batch [84/109], Loss: 0.5005\n  Batch [105/109], Loss: 0.5085\nEpoch [6/25] Complete. Train Loss: 0.5036, Time: 139.07s\nEpoch 6: Starting validation...\nValidation Results - Loss: 0.5163, Accuracy: 74.89%\n  Validation loss improved. Resetting early stopping counter.\nEpoch 7/25: Starting training...\n  Batch [21/109], Loss: 0.4987\n  Batch [42/109], Loss: 0.4850\n  Batch [63/109], Loss: 0.5106\n  Batch [84/109], Loss: 0.4984\n  Batch [105/109], Loss: 0.4913\nEpoch [7/25] Complete. Train Loss: 0.4996, Time: 137.09s\nEpoch 8/25: Starting training...\n  Batch [21/109], Loss: 0.5042\n  Batch [42/109], Loss: 0.5224\n  Batch [63/109], Loss: 0.4953\n  Batch [84/109], Loss: 0.4706\n  Batch [105/109], Loss: 0.4782\nEpoch [8/25] Complete. Train Loss: 0.4967, Time: 137.47s\nEpoch 8: Starting validation...\nValidation Results - Loss: 0.5105, Accuracy: 75.17%\n  Validation loss improved. Resetting early stopping counter.\nEpoch 9/25: Starting training...\n  Batch [21/109], Loss: 0.4995\n  Batch [42/109], Loss: 0.5023\n  Batch [63/109], Loss: 0.5038\n  Batch [84/109], Loss: 0.4733\n  Batch [105/109], Loss: 0.4992\nEpoch [9/25] Complete. Train Loss: 0.4946, Time: 143.02s\nEpoch 10/25: Starting training...\n  Batch [21/109], Loss: 0.5084\n  Batch [42/109], Loss: 0.4902\n  Batch [63/109], Loss: 0.4922\n  Batch [84/109], Loss: 0.5013\n  Batch [105/109], Loss: 0.4966\nEpoch [10/25] Complete. Train Loss: 0.4929, Time: 142.32s\nEpoch 10: Starting validation...\nValidation Results - Loss: 0.5067, Accuracy: 75.43%\n  Validation loss improved. Resetting early stopping counter.\nEpoch 11/25: Starting training...\n  Batch [21/109], Loss: 0.4908\n  Batch [42/109], Loss: 0.4942\n  Batch [63/109], Loss: 0.4825\n  Batch [84/109], Loss: 0.4893\n  Batch [105/109], Loss: 0.4938\nEpoch [11/25] Complete. Train Loss: 0.4912, Time: 138.16s\nEpoch 12/25: Starting training...\n  Batch [21/109], Loss: 0.4953\n  Batch [42/109], Loss: 0.5108\n  Batch [63/109], Loss: 0.4987\n  Batch [84/109], Loss: 0.5024\n  Batch [105/109], Loss: 0.5001\nEpoch [12/25] Complete. Train Loss: 0.4901, Time: 140.88s\nEpoch 12: Starting validation...\nValidation Results - Loss: 0.5045, Accuracy: 75.66%\n  Validation loss improved. Resetting early stopping counter.\nEpoch 13/25: Starting training...\n  Batch [21/109], Loss: 0.4785\n  Batch [42/109], Loss: 0.4800\n  Batch [63/109], Loss: 0.4883\n  Batch [84/109], Loss: 0.4916\n  Batch [105/109], Loss: 0.4768\nEpoch [13/25] Complete. Train Loss: 0.4890, Time: 140.80s\nEpoch 14/25: Starting training...\n  Batch [21/109], Loss: 0.4746\n  Batch [42/109], Loss: 0.4828\n  Batch [63/109], Loss: 0.4901\n  Batch [84/109], Loss: 0.4910\n  Batch [105/109], Loss: 0.4795\nEpoch [14/25] Complete. Train Loss: 0.4883, Time: 138.76s\nEpoch 14: Starting validation...\nValidation Results - Loss: 0.5038, Accuracy: 75.57%\n  Validation loss improved. Resetting early stopping counter.\nEpoch 15/25: Starting training...\n  Batch [21/109], Loss: 0.4964\n  Batch [42/109], Loss: 0.4957\n  Batch [63/109], Loss: 0.4864\n  Batch [84/109], Loss: 0.5067\n  Batch [105/109], Loss: 0.4930\nEpoch [15/25] Complete. Train Loss: 0.4876, Time: 141.08s\nEpoch 16/25: Starting training...\n  Batch [21/109], Loss: 0.4995\n  Batch [42/109], Loss: 0.4794\n  Batch [63/109], Loss: 0.4787\n  Batch [84/109], Loss: 0.4806\n  Batch [105/109], Loss: 0.4978\nEpoch [16/25] Complete. Train Loss: 0.4871, Time: 137.96s\nEpoch 16: Starting validation...\nValidation Results - Loss: 0.5017, Accuracy: 75.72%\n  Validation loss improved. Resetting early stopping counter.\nEpoch 17/25: Starting training...\n  Batch [21/109], Loss: 0.4820\n  Batch [42/109], Loss: 0.4800\n  Batch [63/109], Loss: 0.5049\n  Batch [84/109], Loss: 0.5026\n  Batch [105/109], Loss: 0.4810\nEpoch [17/25] Complete. Train Loss: 0.4865, Time: 138.19s\nEpoch 18/25: Starting training...\n  Batch [21/109], Loss: 0.4756\n  Batch [42/109], Loss: 0.4860\n  Batch [63/109], Loss: 0.4788\n  Batch [84/109], Loss: 0.4922\n  Batch [105/109], Loss: 0.4739\nEpoch [18/25] Complete. Train Loss: 0.4860, Time: 137.38s\nEpoch 18: Starting validation...\nValidation Results - Loss: 0.5007, Accuracy: 75.89%\n  Validation loss improved. Resetting early stopping counter.\nEpoch 19/25: Starting training...\n  Batch [21/109], Loss: 0.4964\n  Batch [42/109], Loss: 0.4742\n  Batch [63/109], Loss: 0.4806\n  Batch [84/109], Loss: 0.4959\n  Batch [105/109], Loss: 0.4956\nEpoch [19/25] Complete. Train Loss: 0.4855, Time: 135.69s\nEpoch 20/25: Starting training...\n  Batch [21/109], Loss: 0.5087\n  Batch [42/109], Loss: 0.4683\n  Batch [63/109], Loss: 0.4685\n  Batch [84/109], Loss: 0.4721\n  Batch [105/109], Loss: 0.4774\nEpoch [20/25] Complete. Train Loss: 0.4852, Time: 135.89s\nEpoch 20: Starting validation...\nValidation Results - Loss: 0.5002, Accuracy: 75.93%\n  Validation loss improved. Resetting early stopping counter.\nEpoch 21/25: Starting training...\n  Batch [21/109], Loss: 0.4826\n  Batch [42/109], Loss: 0.4798\n  Batch [63/109], Loss: 0.4595\n  Batch [84/109], Loss: 0.5089\n  Batch [105/109], Loss: 0.4609\nEpoch [21/25] Complete. Train Loss: 0.4849, Time: 136.92s\nEpoch 22/25: Starting training...\n  Batch [21/109], Loss: 0.4854\n  Batch [42/109], Loss: 0.4775\n  Batch [63/109], Loss: 0.4840\n  Batch [84/109], Loss: 0.4677\n  Batch [105/109], Loss: 0.4757\nEpoch [22/25] Complete. Train Loss: 0.4844, Time: 135.36s\nEpoch 22: Starting validation...\nValidation Results - Loss: 0.4997, Accuracy: 75.98%\n  Validation loss improved. Resetting early stopping counter.\nEpoch 23/25: Starting training...\n  Batch [21/109], Loss: 0.4786\n  Batch [42/109], Loss: 0.4713\n  Batch [63/109], Loss: 0.4971\n  Batch [84/109], Loss: 0.4898\n  Batch [105/109], Loss: 0.4749\nEpoch [23/25] Complete. Train Loss: 0.4845, Time: 134.17s\nEpoch 24/25: Starting training...\n  Batch [21/109], Loss: 0.4779\n  Batch [42/109], Loss: 0.4814\n  Batch [63/109], Loss: 0.5052\n  Batch [84/109], Loss: 0.4651\n  Batch [105/109], Loss: 0.4827\nEpoch [24/25] Complete. Train Loss: 0.4842, Time: 140.50s\nEpoch 24: Starting validation...\nValidation Results - Loss: 0.4986, Accuracy: 75.98%\n  Validation loss improved. Resetting early stopping counter.\nEpoch 25/25: Starting training...\n  Batch [21/109], Loss: 0.4890\n  Batch [42/109], Loss: 0.4849\n  Batch [63/109], Loss: 0.4911\n  Batch [84/109], Loss: 0.4792\n  Batch [105/109], Loss: 0.4660\nEpoch [25/25] Complete. Train Loss: 0.4836, Time: 136.88s\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Training and validation loop\nfor epoch in range(num_epochs):\n    start_time = time.time()  # Track time at the start of each epoch\n    model.train()  # Set model to training mode\n    running_loss = 0.0  # Reset cumulative training loss for this epoch\n\n    print(f\"Epoch {epoch + 1}/{num_epochs}: Starting training...\")\n    for batch_idx, (images, labels, _) in enumerate(train_loader):  # Loop through training batches\n        images, labels = images.to(device), labels.to(device)  # Move data to the selected device\n        optimizer.zero_grad()  # Clear gradients from the previous step\n\n        # Forward pass with mixed precision for efficiency\n        with autocast():\n            outputs = model(images)  # Get predictions from the model\n            loss = criterion(outputs, labels)  # Calculate the loss\n\n        # Backward pass and optimization step\n        scaler.scale(loss).backward()  # Scale the loss for mixed precision\n        scaler.step(optimizer)  # Update model weights\n        scaler.update()  # Update the scaler for mixed precision\n\n        running_loss += loss.item()  # Accumulate training loss\n\n        # Optional: Log batch-level progress\n        if (batch_idx + 1) % (len(train_loader) // 5) == 0:  # Log 5 times per epoch\n            print(f\"  Batch [{batch_idx + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n\n    # Calculate average training loss for the epoch\n    avg_train_loss = running_loss / len(train_loader)\n    epoch_time = time.time() - start_time  # Calculate epoch duration\n    print(f\"Epoch [{epoch + 1}/{num_epochs}] Complete. Train Loss: {avg_train_loss:.4f}, Time: {epoch_time:.2f}s\")\n\n    # Validation step (only every `validate_every` epochs)\n    if (epoch + 1) % validate_every == 0:\n        print(f\"Epoch {epoch + 1}: Starting validation...\")\n        model.eval()  # Set model to evaluation mode\n        valid_loss = 0.0  # Reset cumulative validation loss\n        correct = 0  # Count of correct predictions\n        total = 0  # Total number of samples\n\n        with torch.no_grad():  # No gradients needed during validation\n            for images, labels, _ in valid_loader:  # Loop through validation batches\n                images, labels = images.to(device), labels.to(device)  # Move data to the selected device\n\n                outputs = model(images)  # Get predictions\n                loss = criterion(outputs, labels)  # Calculate the loss\n                valid_loss += loss.item()  # Accumulate validation loss\n\n                # Calculate accuracy\n                _, predicted = torch.max(outputs, 1)  # Get predicted class\n                total += labels.size(0)  # Update total sample count\n                correct += (predicted == labels).sum().item()  # Update correct prediction count\n\n        # Calculate validation loss and accuracy\n        avg_valid_loss = valid_loss / len(valid_loader)\n        accuracy = 100 * correct / total\n        print(f\"Validation Results - Loss: {avg_valid_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n\n        # Early stopping logic\n        if avg_valid_loss < best_valid_loss:\n            best_valid_loss = avg_valid_loss  # Update the best validation loss\n            no_improve_epochs = 0  # Reset patience counter\n            print(\"  Validation loss improved. Resetting early stopping counter.\")\n        else:\n            no_improve_epochs += 1  # Increment patience counter\n            print(f\"  No improvement in validation loss. Patience: {no_improve_epochs}/{patience}\")\n            if no_improve_epochs >= patience:\n                print(\"Early stopping triggered. Stopping training.\")\n                break  # Exit the training loop\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T19:59:14.830736Z","iopub.execute_input":"2024-11-17T19:59:14.831474Z","iopub.status.idle":"2024-11-17T20:25:39.586391Z","shell.execute_reply.started":"2024-11-17T19:59:14.831430Z","shell.execute_reply":"2024-11-17T20:25:39.585147Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10: Starting training...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/70649097.py:13: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n","output_type":"stream"},{"name":"stdout","text":"  Batch [21/109], Loss: 0.4262\n  Batch [42/109], Loss: 0.3906\n  Batch [63/109], Loss: 0.3635\n  Batch [84/109], Loss: 0.3514\n  Batch [105/109], Loss: 0.3698\nEpoch [1/10] Complete. Train Loss: 0.4130, Time: 152.43s\nEpoch 2/10: Starting training...\n  Batch [21/109], Loss: 0.3406\n  Batch [42/109], Loss: 0.3388\n  Batch [63/109], Loss: 0.3426\n  Batch [84/109], Loss: 0.3607\n  Batch [105/109], Loss: 0.3479\nEpoch [2/10] Complete. Train Loss: 0.3491, Time: 147.53s\nEpoch 2: Starting validation...\nValidation Results - Loss: 0.5692, Accuracy: 78.66%\n  No improvement in validation loss. Patience: 1/3\nEpoch 3/10: Starting training...\n  Batch [21/109], Loss: 0.3239\n  Batch [42/109], Loss: 0.3331\n  Batch [63/109], Loss: 0.3528\n  Batch [84/109], Loss: 0.3566\n  Batch [105/109], Loss: 0.3494\nEpoch [3/10] Complete. Train Loss: 0.3333, Time: 146.63s\nEpoch 4/10: Starting training...\n  Batch [21/109], Loss: 0.2820\n  Batch [42/109], Loss: 0.2974\n  Batch [63/109], Loss: 0.3257\n  Batch [84/109], Loss: 0.3102\n  Batch [105/109], Loss: 0.3310\nEpoch [4/10] Complete. Train Loss: 0.3104, Time: 146.89s\nEpoch 4: Starting validation...\nValidation Results - Loss: 0.4367, Accuracy: 79.51%\n  Validation loss improved. Resetting early stopping counter.\nEpoch 5/10: Starting training...\n  Batch [21/109], Loss: 0.2338\n  Batch [42/109], Loss: 0.2663\n  Batch [63/109], Loss: 0.2807\n  Batch [84/109], Loss: 0.3101\n  Batch [105/109], Loss: 0.2769\nEpoch [5/10] Complete. Train Loss: 0.2851, Time: 148.15s\nEpoch 6/10: Starting training...\n  Batch [21/109], Loss: 0.2161\n  Batch [42/109], Loss: 0.2411\n  Batch [63/109], Loss: 0.2710\n  Batch [84/109], Loss: 0.2526\n  Batch [105/109], Loss: 0.2575\nEpoch [6/10] Complete. Train Loss: 0.2487, Time: 148.91s\nEpoch 6: Starting validation...\nValidation Results - Loss: 0.5548, Accuracy: 80.41%\n  No improvement in validation loss. Patience: 1/3\nEpoch 7/10: Starting training...\n  Batch [21/109], Loss: 0.1827\n  Batch [42/109], Loss: 0.2141\n  Batch [63/109], Loss: 0.2175\n  Batch [84/109], Loss: 0.2220\n  Batch [105/109], Loss: 0.2171\nEpoch [7/10] Complete. Train Loss: 0.2037, Time: 149.86s\nEpoch 8/10: Starting training...\n  Batch [21/109], Loss: 0.1373\n  Batch [42/109], Loss: 0.1654\n  Batch [63/109], Loss: 0.1678\n  Batch [84/109], Loss: 0.1753\n  Batch [105/109], Loss: 0.1918\nEpoch [8/10] Complete. Train Loss: 0.1614, Time: 149.93s\nEpoch 8: Starting validation...\nValidation Results - Loss: 0.6164, Accuracy: 77.17%\n  No improvement in validation loss. Patience: 2/3\nEpoch 9/10: Starting training...\n  Batch [21/109], Loss: 0.1242\n  Batch [42/109], Loss: 0.1097\n  Batch [63/109], Loss: 0.1207\n  Batch [84/109], Loss: 0.1322\n  Batch [105/109], Loss: 0.1378\nEpoch [9/10] Complete. Train Loss: 0.1226, Time: 147.87s\nEpoch 10/10: Starting training...\n  Batch [21/109], Loss: 0.0789\n  Batch [42/109], Loss: 0.0790\n  Batch [63/109], Loss: 0.0939\n  Batch [84/109], Loss: 0.0776\n  Batch [105/109], Loss: 0.1131\nEpoch [10/10] Complete. Train Loss: 0.0908, Time: 147.25s\nEpoch 10: Starting validation...\nValidation Results - Loss: 0.8698, Accuracy: 79.19%\n  No improvement in validation loss. Patience: 3/3\nEarly stopping triggered. Stopping training.\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"num_epochs = 10\noptimizer = optim.Adam(model.parameters(), lr=0.00001)\n# Training and validation loop\nfor epoch in range(num_epochs):\n    start_time = time.time()  # Track time at the start of each epoch\n    model.train()  # Set model to training mode\n    running_loss = 0.0  # Reset cumulative training loss for this epoch\n\n    print(f\"Epoch {epoch + 1}/{num_epochs}: Starting training...\")\n    for batch_idx, (images, labels, _) in enumerate(train_loader):  # Loop through training batches\n        images, labels = images.to(device), labels.to(device)  # Move data to the selected device\n        optimizer.zero_grad()  # Clear gradients from the previous step\n\n        with autocast():\n            outputs = model(images)  \n            loss = criterion(outputs, labels) \n\n        scaler.scale(loss).backward()  \n        scaler.step(optimizer)  \n        scaler.update()  \n\n        running_loss += loss.item()  \n\n        if (batch_idx + 1) % (len(train_loader) // 5) == 0:  \n            print(f\"  Batch [{batch_idx + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n\n    avg_train_loss = running_loss / len(train_loader)\n    epoch_time = time.time() - start_time  \n    print(f\"Epoch [{epoch + 1}/{num_epochs}] Complete. Train Loss: {avg_train_loss:.4f}, Time: {epoch_time:.2f}s\")\n\n    if (epoch + 1) % validate_every == 0:\n        print(f\"Epoch {epoch + 1}: Starting validation...\")\n        model.eval()  \n        valid_loss = 0.0  \n        correct = 0  \n        total = 0  \n\n        with torch.no_grad():  \n            for images, labels, _ in valid_loader: \n                images, labels = images.to(device), labels.to(device)  \n                outputs = model(images)  # Get predictions\n                loss = criterion(outputs, labels)  # Calculate the loss\n                valid_loss += loss.item()  # Accumulate validation loss\n\n               \n                _, predicted = torch.max(outputs, 1)  \n                total += labels.size(0)  \n                correct += (predicted == labels).sum().item()  \n\n       \n        avg_valid_loss = valid_loss / len(valid_loader)\n        accuracy = 100 * correct / total\n        print(f\"Validation Results - Loss: {avg_valid_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n\n        \n        if avg_valid_loss < best_valid_loss:\n            best_valid_loss = avg_valid_loss  # Update the best validation loss\n            no_improve_epochs = 0  # Reset patience counter\n            print(\"  Validation loss improved. Resetting early stopping counter.\")\n        else:\n            no_improve_epochs += 1  # Increment patience counter\n            print(f\"  No improvement in validation loss. Patience: {no_improve_epochs}/{patience}\")\n            if no_improve_epochs >= patience:\n                print(\"Early stopping triggered. Stopping training.\")\n                break  # Exit the training loop\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:29:12.387399Z","iopub.execute_input":"2024-11-17T20:29:12.387821Z","iopub.status.idle":"2024-11-17T20:34:32.181887Z","shell.execute_reply.started":"2024-11-17T20:29:12.387782Z","shell.execute_reply":"2024-11-17T20:34:32.180655Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10: Starting training...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/2374052875.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n","output_type":"stream"},{"name":"stdout","text":"  Batch [21/109], Loss: 0.0453\n  Batch [42/109], Loss: 0.0497\n  Batch [63/109], Loss: 0.0424\n  Batch [84/109], Loss: 0.0412\n  Batch [105/109], Loss: 0.0443\nEpoch [1/10] Complete. Train Loss: 0.0431, Time: 149.14s\nEpoch 2/10: Starting training...\n  Batch [21/109], Loss: 0.0372\n  Batch [42/109], Loss: 0.0295\n  Batch [63/109], Loss: 0.0324\n  Batch [84/109], Loss: 0.0329\n  Batch [105/109], Loss: 0.0343\nEpoch [2/10] Complete. Train Loss: 0.0274, Time: 150.97s\nEpoch 2: Starting validation...\nValidation Results - Loss: 0.9119, Accuracy: 79.59%\n  No improvement in validation loss. Patience: 4/3\nEarly stopping triggered. Stopping training.\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"model.eval()\ntest_loss = 0.0\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for images, labels, _ in test_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        test_loss += loss.item()\n\n        # Accuracy calculation\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\navg_test_loss = test_loss / len(test_loader)\ntest_accuracy = 100 * correct / total\nprint(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-11-17T20:37:13.668948Z","iopub.execute_input":"2024-11-17T20:37:13.669975Z","iopub.status.idle":"2024-11-17T20:37:33.095444Z","shell.execute_reply.started":"2024-11-17T20:37:13.669924Z","shell.execute_reply":"2024-11-17T20:37:33.094275Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Test Loss: 0.8629, Test Accuracy: 80.06%\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"torch.save(model.state_dict(), \"/kaggle/working/fine_tuned_best_ever_resnet18\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:39:56.657171Z","iopub.execute_input":"2024-11-17T20:39:56.658134Z","iopub.status.idle":"2024-11-17T20:39:56.750869Z","shell.execute_reply.started":"2024-11-17T20:39:56.658088Z","shell.execute_reply":"2024-11-17T20:39:56.750085Z"}},"outputs":[],"execution_count":37}]}