{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":37705,"sourceType":"datasetVersion","datasetId":29561},{"sourceId":169970,"sourceType":"modelInstanceVersion","modelInstanceId":144601,"modelId":167163}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:51:43.304852Z","iopub.execute_input":"2024-11-17T20:51:43.305396Z","iopub.status.idle":"2024-11-17T20:51:43.310974Z","shell.execute_reply.started":"2024-11-17T20:51:43.305339Z","shell.execute_reply":"2024-11-17T20:51:43.309783Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install aif360","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:51:43.330244Z","iopub.execute_input":"2024-11-17T20:51:43.330709Z","iopub.status.idle":"2024-11-17T20:51:56.500401Z","shell.execute_reply.started":"2024-11-17T20:51:43.330664Z","shell.execute_reply":"2024-11-17T20:51:56.499246Z"}},"outputs":[{"name":"stdout","text":"Collecting aif360\n  Downloading aif360-0.6.1-py3-none-any.whl.metadata (5.0 kB)\nRequirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.10/site-packages (from aif360) (1.26.4)\nRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from aif360) (1.14.1)\nRequirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from aif360) (2.2.2)\nRequirement already satisfied: scikit-learn>=1.0 in /opt/conda/lib/python3.10/site-packages (from aif360) (1.2.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from aif360) (3.7.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.0->aif360) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.0->aif360) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24.0->aif360) (2024.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0->aif360) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0->aif360) (3.5.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->aif360) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->aif360) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->aif360) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->aif360) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->aif360) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->aif360) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->aif360) (3.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->aif360) (1.16.0)\nDownloading aif360-0.6.1-py3-none-any.whl (259 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.7/259.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: aif360\nSuccessfully installed aif360-0.6.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\n\nimport timm\n\nimport matplotlib.pyplot as plt\nimport sys\nfrom tqdm.notebook import tqdm\n\nimport os\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\n\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nfrom torchvision import datasets\nfrom torchvision import transforms\n\nfrom PIL import Image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:51:56.503067Z","iopub.execute_input":"2024-11-17T20:51:56.503492Z","iopub.status.idle":"2024-11-17T20:52:02.781753Z","shell.execute_reply.started":"2024-11-17T20:51:56.503447Z","shell.execute_reply":"2024-11-17T20:52:02.780939Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#Dynamically set device\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {device}\")\n\nGRAYSCALE = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:52:02.782807Z","iopub.execute_input":"2024-11-17T20:52:02.783273Z","iopub.status.idle":"2024-11-17T20:52:02.810906Z","shell.execute_reply.started":"2024-11-17T20:52:02.783238Z","shell.execute_reply":"2024-11-17T20:52:02.810004Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Model - Fine-tuned on CelebA","metadata":{}},{"cell_type":"code","source":"import torchvision.models as models\n\nmodel = models.resnet18()\n\n#Modify the final fully connected layer to output two classes\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(num_features, 2) \n\nmodel_path = \"/kaggle/input/resnet18_baseline_celeba/pytorch/default/1/fine_tuned_best_ever_resnet18\"\nmodel.load_state_dict(torch.load(model_path, weights_only = True))\n\n\nfor param in model.parameters():\n    param.requires_grad = False\n\n#last layer trainable\nfor param in model.fc.parameters():\n        param.requires_grad = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:52:02.813107Z","iopub.execute_input":"2024-11-17T20:52:02.813463Z","iopub.status.idle":"2024-11-17T20:52:03.938507Z","shell.execute_reply.started":"2024-11-17T20:52:02.813431Z","shell.execute_reply":"2024-11-17T20:52:03.937677Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"#criterion, optimizer, and other parameters\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nnum_epochs = 5\nvalidate_every = 2\npatience = 3  #Number of epochs to wait before early stopping","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:52:03.939635Z","iopub.execute_input":"2024-11-17T20:52:03.939946Z","iopub.status.idle":"2024-11-17T20:52:03.945606Z","shell.execute_reply.started":"2024-11-17T20:52:03.939914Z","shell.execute_reply":"2024-11-17T20:52:03.944619Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Loading Dataset in train loaders","metadata":{}},{"cell_type":"code","source":"#The target label is attractiveness and protected attribute is gender.\n\ndata_root = \"/kaggle/input/celeba-dataset/\"\nlabel_attr = \"Attractive\"\nprotected_attr = \"Male\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:52:03.946865Z","iopub.execute_input":"2024-11-17T20:52:03.947254Z","iopub.status.idle":"2024-11-17T20:52:03.954704Z","shell.execute_reply.started":"2024-11-17T20:52:03.947209Z","shell.execute_reply":"2024-11-17T20:52:03.953903Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class CelebaDataset(Dataset):\n    \n    def __init__(self, csv_path, img_dir, transform=None, label_attr = 'Attractive', protected_attr = 'Male'):\n        \n        df = pd.read_csv(csv_path, index_col=0)\n        self.img_dir = img_dir\n        self.csv_path = csv_path\n        self.img_names = df.index.values\n        self.y = df[label_attr].values\n        self.p = df[protected_attr].values\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        img = Image.open(os.path.join(self.img_dir,\n                      self.img_names[index]))\n\n        if self.transform is not None:\n            img = self.transform(img)\n            \n        label = self.y[index]\n        protected = self.p[index]\n        return img, label, protected\n        \n    def __len__(self):\n        return self.y.shape[0]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:52:03.955957Z","iopub.execute_input":"2024-11-17T20:52:03.956420Z","iopub.status.idle":"2024-11-17T20:52:03.965232Z","shell.execute_reply.started":"2024-11-17T20:52:03.956376Z","shell.execute_reply":"2024-11-17T20:52:03.964257Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"other_data_root = '/kaggle/working/' #for writing purposes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:52:03.966490Z","iopub.execute_input":"2024-11-17T20:52:03.966773Z","iopub.status.idle":"2024-11-17T20:52:03.974109Z","shell.execute_reply.started":"2024-11-17T20:52:03.966735Z","shell.execute_reply":"2024-11-17T20:52:03.973253Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def prepare_dataset(label_attr = 'Attractive', protected_attr = 'Male'):\n\n    print('Using label attribute:', label_attr)\n\n    df1 = pd.read_csv(data_root + 'list_attr_celeba.csv',usecols=[label_attr, protected_attr])\n    #Make 0 (female) & 1 (male) labels instead of -1 & 1\n    df1.loc[df1[label_attr] == -1, label_attr] = 0\n    df1.loc[df1[protected_attr] == -1, protected_attr] = 0\n    \n\n    df2 = pd.read_csv(data_root + 'list_eval_partition.csv')\n    df2.columns = ['image_id', 'partition']\n    image_series = df2['image_id']\n    df2 = df2.set_index('image_id')\n\n    df1 = df1.set_index(image_series)\n\n    df3 = pd.concat([df1,df2],axis=1)\n    \n    df3.to_csv(other_data_root + 'celeba-attractive-partitions.csv')\n\n    df4 = pd.read_csv(other_data_root + 'celeba-attractive-partitions.csv', index_col=0)\n\n    df4.loc[df4['partition'] == 0].to_csv(other_data_root + 'celeba-attractive-train.csv')\n    df4.loc[df4['partition'] == 1].to_csv(other_data_root + 'celeba-attractive-valid.csv')\n    df4.loc[df4['partition'] == 2].to_csv(other_data_root + 'celeba-attractive-test.csv')\n    \ndef get_loaders():\n\n    prepare_dataset(label_attr, protected_attr)\n    \n    #Note that transforms.ToTensor()\n    #already divides pixels by 255. internally\n\n    custom_transform = transforms.Compose([transforms.CenterCrop((178, 178)),\n                                           transforms.Resize((128, 128)),\n                                           transforms.ToTensor()])\n\n    train_dataset = CelebaDataset(csv_path=other_data_root + 'celeba-attractive-train.csv',\n                                  img_dir=data_root + 'img_align_celeba/img_align_celeba',\n                                  transform=custom_transform,\n                                  label_attr=label_attr,\n                                  protected_attr = protected_attr)\n\n    valid_dataset = CelebaDataset(csv_path=other_data_root + 'celeba-attractive-valid.csv',\n                                  img_dir=data_root + 'img_align_celeba/img_align_celeba',\n                                  transform=custom_transform,\n                                  label_attr=label_attr,\n                                  protected_attr = protected_attr)\n\n    test_dataset = CelebaDataset(csv_path=other_data_root + 'celeba-attractive-test.csv',\n                                 img_dir=data_root + 'img_align_celeba/img_align_celeba',\n                                 transform=custom_transform,\n                                 label_attr=label_attr,\n                                 protected_attr = protected_attr)\n\n    train_loader = DataLoader(dataset=train_dataset,\n                              batch_size=BATCH_SIZE,\n                              shuffle=True,\n                              num_workers=4)\n\n    valid_loader = DataLoader(dataset=valid_dataset,\n                              batch_size=BATCH_SIZE,\n                              shuffle=False,\n                              num_workers=4)\n    \n    test_loader = DataLoader(dataset=test_dataset,\n                             batch_size=BATCH_SIZE,\n                             shuffle=False,\n                             num_workers=4)\n\n    return train_loader, valid_loader, test_loader\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:52:03.975466Z","iopub.execute_input":"2024-11-17T20:52:03.975774Z","iopub.status.idle":"2024-11-17T20:52:03.991177Z","shell.execute_reply.started":"2024-11-17T20:52:03.975743Z","shell.execute_reply":"2024-11-17T20:52:03.990221Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"BATCH_SIZE = 256","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:52:03.994416Z","iopub.execute_input":"2024-11-17T20:52:03.994707Z","iopub.status.idle":"2024-11-17T20:52:04.005331Z","shell.execute_reply.started":"2024-11-17T20:52:03.994677Z","shell.execute_reply":"2024-11-17T20:52:04.004321Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_loader, valid_loader, test_loader = get_loaders()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:52:04.006402Z","iopub.execute_input":"2024-11-17T20:52:04.006684Z","iopub.status.idle":"2024-11-17T20:52:06.050733Z","shell.execute_reply.started":"2024-11-17T20:52:04.006654Z","shell.execute_reply":"2024-11-17T20:52:06.049943Z"}},"outputs":[{"name":"stdout","text":"Using label attribute: Attractive\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"print(f\"The number of train batches : {len(train_loader)}\")\nprint(f\"The number of validation batches : {len(valid_loader)}\")\nprint(f\"The number of test batches : {len(test_loader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:52:06.051838Z","iopub.execute_input":"2024-11-17T20:52:06.052144Z","iopub.status.idle":"2024-11-17T20:52:06.057840Z","shell.execute_reply.started":"2024-11-17T20:52:06.052105Z","shell.execute_reply":"2024-11-17T20:52:06.056829Z"}},"outputs":[{"name":"stdout","text":"The number of train batches : 636\nThe number of validation batches : 78\nThe number of test batches : 78\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# Basic Testing","metadata":{}},{"cell_type":"code","source":"def test_model(model_in_fn, test_loader, gpu_yes = True):\n    model_in_fn.eval()  # Set model to evaluation mode\n    if gpu_yes:\n        device = 'cuda'\n        model_in_fn.to(device)\n    else:\n        device='cpu'\n        model_in_fn.to('cpu')\n    # Initialize counters\n    correct, total = 0, 0\n    male_correct, female_correct = 0, 0\n    male_total, female_total = 0, 0\n    \n    # Initialize confusion matrix components for males and females\n    male_tp, male_fp, male_tn, male_fn = 0, 0, 0, 0\n    female_tp, female_fp, female_tn, female_fn = 0, 0, 0, 0\n    all_ones, all_zeros = 0, 0\n    \n    with torch.no_grad():\n        for images, labels, genders in test_loader:\n            images, labels, genders = images.to(device), labels.to(device), genders.to(device)\n            outputs = model_in_fn(images)\n            _, predicted = torch.max(outputs, 1)\n            \n            # Update overall accuracy\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n            \n            # Count total positive and negative cases\n            all_ones += (labels == 1).sum().item()\n            all_zeros += (labels == 0).sum().item()\n            \n            # Separate male and female predictions\n            male_mask = (genders == 1)\n            female_mask = (genders == 0)\n            \n            # Update accuracy counts\n            male_correct += (predicted[male_mask] == labels[male_mask]).sum().item()\n            female_correct += (predicted[female_mask] == labels[female_mask]).sum().item()\n            male_total += male_mask.sum().item()\n            female_total += female_mask.sum().item()\n            \n            # Update confusion matrix components for males\n            male_tp += ((predicted[male_mask] == 1) & (labels[male_mask] == 1)).sum().item()\n            male_fp += ((predicted[male_mask] == 1) & (labels[male_mask] == 0)).sum().item()\n            male_tn += ((predicted[male_mask] == 0) & (labels[male_mask] == 0)).sum().item()\n            male_fn += ((predicted[male_mask] == 0) & (labels[male_mask] == 1)).sum().item()\n            \n            # Update confusion matrix components for females\n            female_tp += ((predicted[female_mask] == 1) & (labels[female_mask] == 1)).sum().item()\n            female_fp += ((predicted[female_mask] == 1) & (labels[female_mask] == 0)).sum().item()\n            female_tn += ((predicted[female_mask] == 0) & (labels[female_mask] == 0)).sum().item()\n            female_fn += ((predicted[female_mask] == 0) & (labels[female_mask] == 1)).sum().item()\n    \n    # Calculate metrics\n    overall_accuracy = correct / total\n    male_accuracy = male_correct / male_total if male_total > 0 else 0\n    female_accuracy = female_correct / female_total if female_total > 0 else 0\n    \n    # Calculate TPR and FPR correctly\n    male_tpr = male_tp / (male_tp + male_fn) if (male_tp + male_fn) > 0 else 0\n    female_tpr = female_tp / (female_tp + female_fn) if (female_tp + female_fn) > 0 else 0\n    male_fpr = male_fp / (male_fp + male_tn) if (male_fp + male_tn) > 0 else 0\n    female_fpr = female_fp / (female_fp + female_tn) if (female_fp + female_tn) > 0 else 0\n    \n    # Fairness metrics\n    DEO = abs(male_tpr - female_tpr)\n    FPR_diff = abs(male_fpr - female_fpr)\n    \n    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n    print(f\"Male Accuracy: {male_accuracy:.4f}\")\n    print(f\"Female Accuracy: {female_accuracy:.2f}\")\n    print(f\"Male TPR: {male_tpr:.2f}\")\n    print(f\"Female TPR: {female_tpr:.2f}\")\n    print(f\"Male FPR: {male_fpr:.2f}\")\n    print(f\"Female FPR: {female_fpr:.2f}\")\n    print(f\"Demographic Equal Opportunity (DEO): {DEO:.2f}\")\n    print(f\"False Positive Rate Difference (FPR): {FPR_diff:.2f}\")\n    \n    return {\n        \"overall_accuracy\": overall_accuracy,\n        \"male_accuracy\": male_accuracy,\n        \"female_accuracy\": female_accuracy,\n        \"male_tpr\": male_tpr,\n        \"female_tpr\": female_tpr,\n        \"male_fpr\": male_fpr,\n        \"female_fpr\": female_fpr,\n        \"DEO\": DEO,\n        \"FPR_difference\": FPR_diff,\n        \"Attractive yes in test\": all_ones/total,\n        \"Attractive no in test\": all_zeros/total,\n        \"Batch Size\": BATCH_SIZE\n    }, model_in_fn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:52:06.059158Z","iopub.execute_input":"2024-11-17T20:52:06.059478Z","iopub.status.idle":"2024-11-17T20:52:06.080248Z","shell.execute_reply.started":"2024-11-17T20:52:06.059447Z","shell.execute_reply":"2024-11-17T20:52:06.079255Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"test_model(model, test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:52:06.081305Z","iopub.execute_input":"2024-11-17T20:52:06.081602Z","iopub.status.idle":"2024-11-17T20:52:45.751980Z","shell.execute_reply.started":"2024-11-17T20:52:06.081571Z","shell.execute_reply":"2024-11-17T20:52:45.750926Z"}},"outputs":[{"name":"stdout","text":"Overall Accuracy: 0.8006\nMale Accuracy: 0.8161\nFemale Accuracy: 0.79\nMale TPR: 0.65\nFemale TPR: 0.86\nMale FPR: 0.13\nFemale FPR: 0.33\nDemographic Equal Opportunity (DEO): 0.21\nFalse Positive Rate Difference (FPR): 0.20\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"({'overall_accuracy': 0.8005710850616171,\n  'male_accuracy': 0.8160725858716785,\n  'female_accuracy': 0.7908059116518331,\n  'male_tpr': 0.6504702194357367,\n  'female_tpr': 0.8567134268537074,\n  'male_fpr': 0.12928805378383038,\n  'female_fpr': 0.33262960356556415,\n  'DEO': 0.20624320741797075,\n  'FPR_difference': 0.20334154978173377,\n  'Attractive yes in test': 0.49584209998998097,\n  'Attractive no in test': 0.504157900010019,\n  'Batch Size': 256},\n ResNet(\n   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n   (relu): ReLU(inplace=True)\n   (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n   (layer1): Sequential(\n     (0): BasicBlock(\n       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       (relu): ReLU(inplace=True)\n       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     )\n     (1): BasicBlock(\n       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       (relu): ReLU(inplace=True)\n       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     )\n   )\n   (layer2): Sequential(\n     (0): BasicBlock(\n       (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       (relu): ReLU(inplace=True)\n       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       (downsample): Sequential(\n         (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n         (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (1): BasicBlock(\n       (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       (relu): ReLU(inplace=True)\n       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     )\n   )\n   (layer3): Sequential(\n     (0): BasicBlock(\n       (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       (relu): ReLU(inplace=True)\n       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       (downsample): Sequential(\n         (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (1): BasicBlock(\n       (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       (relu): ReLU(inplace=True)\n       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     )\n   )\n   (layer4): Sequential(\n     (0): BasicBlock(\n       (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       (relu): ReLU(inplace=True)\n       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       (downsample): Sequential(\n         (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       )\n     )\n     (1): BasicBlock(\n       (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n       (relu): ReLU(inplace=True)\n       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     )\n   )\n   (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n   (fc): Linear(in_features=512, out_features=2, bias=True)\n ))"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"# calibrated_eq_odds_postprocessing - code from IBM F 360","metadata":{}},{"cell_type":"code","source":"# Original work Copyright (c) 2017 Geoff Pleiss\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n#\n# Modified work Copyright 2018 IBM Corporation\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n# use this file except in compliance with the License. You may obtain a copy of\n# the License at http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software distributed\n# under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR\n# CONDITIONS OF ANY KIND, either express or implied. See the License for the\n# specific language governing permissions and limitations under the License.\nimport numpy as np\n\nfrom aif360.algorithms import Transformer\nfrom aif360.metrics import ClassificationMetric, utils","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:52:45.753337Z","iopub.execute_input":"2024-11-17T20:52:45.753652Z","iopub.status.idle":"2024-11-17T20:52:57.788111Z","shell.execute_reply.started":"2024-11-17T20:52:45.753608Z","shell.execute_reply":"2024-11-17T20:52:57.787334Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class CalibratedEqOddsPostprocessing(Transformer):\n    \"\"\"Calibrated equalized odds postprocessing is a post-processing technique\n    that optimizes over calibrated classifier score outputs to find\n    probabilities with which to change output labels with an equalized odds\n    objective [7]_.\n\n    References:\n        .. [7] G. Pleiss, M. Raghavan, F. Wu, J. Kleinberg, and\n           K. Q. Weinberger, \"On Fairness and Calibration,\" Conference on Neural\n           Information Processing Systems, 2017\n\n    Adapted from:\n    https://github.com/gpleiss/equalized_odds_and_calibration/blob/master/calib_eq_odds.py\n    \"\"\"\n\n    def __init__(self, unprivileged_groups, privileged_groups,\n                 cost_constraint='weighted', seed=None):\n        \"\"\"\n        Args:\n            unprivileged_groups (dict or list(dict)): Representation for\n                unprivileged group.\n            privileged_groups (dict or list(dict)): Representation for\n                privileged group.\n            cost_contraint: fpr, fnr or weighted\n            seed (int, optional): Seed to make `predict` repeatable.\n        \"\"\"\n        super(CalibratedEqOddsPostprocessing, self).__init__(\n            unprivileged_groups=unprivileged_groups,\n            privileged_groups=privileged_groups,\n            seed=seed)\n\n        self.seed = seed\n        self.model_params = None\n        self.unprivileged_groups = [unprivileged_groups] \\\n            if isinstance(unprivileged_groups, dict) else unprivileged_groups\n        self.privileged_groups = [privileged_groups] \\\n            if isinstance(privileged_groups, dict) else privileged_groups\n        self.cost_constraint = cost_constraint\n        if self.cost_constraint == 'fnr':\n            self.fn_rate = 1\n            self.fp_rate = 0\n        elif self.cost_constraint == 'fpr':\n            self.fn_rate = 0\n            self.fp_rate = 1\n        elif self.cost_constraint == 'weighted':\n            self.fn_rate = 1\n            self.fp_rate = 1\n\n        self.base_rate_priv = 0.0\n        self.base_rate_unpriv = 0.0\n\n    def fit(self, dataset_true, dataset_pred):\n        \"\"\"Compute parameters for equalizing generalized odds using true and\n        predicted scores, while preserving calibration.\n\n        Args:\n            dataset_true (BinaryLabelDataset): Dataset containing true `labels`.\n            dataset_pred (BinaryLabelDataset): Dataset containing predicted\n                `scores`.\n\n        Returns:\n            CalibratedEqOddsPostprocessing: Returns self.\n        \"\"\"\n\n        # Create boolean conditioning vectors for protected groups\n        cond_vec_priv = utils.compute_boolean_conditioning_vector(\n            dataset_pred.protected_attributes,\n            dataset_pred.protected_attribute_names,\n            self.privileged_groups)\n        cond_vec_unpriv = utils.compute_boolean_conditioning_vector(\n            dataset_pred.protected_attributes,\n            dataset_pred.protected_attribute_names,\n            self.unprivileged_groups)\n\n        cm = ClassificationMetric(dataset_true, dataset_pred,\n                                  unprivileged_groups=self.unprivileged_groups,\n                                  privileged_groups=self.privileged_groups)\n        self.base_rate_priv = cm.base_rate(privileged=True)\n        self.base_rate_unpriv = cm.base_rate(privileged=False)\n\n        # Create a dataset with \"trivial\" predictions\n        dataset_trivial = dataset_pred.copy(deepcopy=True)\n        dataset_trivial.scores[cond_vec_priv] = cm.base_rate(privileged=True)\n        dataset_trivial.scores[cond_vec_unpriv] = cm.base_rate(privileged=False)\n        cm_triv = ClassificationMetric(dataset_true, dataset_trivial,\n            unprivileged_groups=self.unprivileged_groups,\n            privileged_groups=self.privileged_groups)\n\n        if self.fn_rate == 0:\n            priv_cost = cm.generalized_false_positive_rate(privileged=True)\n            unpriv_cost = cm.generalized_false_positive_rate(privileged=False)\n            priv_trivial_cost = cm_triv.generalized_false_positive_rate(privileged=True)\n            unpriv_trivial_cost = cm_triv.generalized_false_positive_rate(privileged=False)\n\n        elif self.fp_rate == 0:\n            priv_cost = cm.generalized_false_negative_rate(privileged=True)\n            unpriv_cost = cm.generalized_false_negative_rate(privileged=False)\n            priv_trivial_cost = cm_triv.generalized_false_negative_rate(privileged=True)\n            unpriv_trivial_cost = cm_triv.generalized_false_negative_rate(privileged=False)\n\n        else:\n            priv_cost = weighted_cost(self.fp_rate, self.fn_rate, cm, privileged=True)\n            unpriv_cost = weighted_cost(self.fp_rate, self.fn_rate, cm, privileged=False)\n            priv_trivial_cost = weighted_cost(self.fp_rate, self.fn_rate, cm_triv, privileged=True)\n            unpriv_trivial_cost = weighted_cost(self.fp_rate, self.fn_rate, cm_triv, privileged=False)\n\n        unpriv_costs_more = unpriv_cost > priv_cost\n        self.priv_mix_rate = (unpriv_cost - priv_cost) / (priv_trivial_cost - priv_cost) if unpriv_costs_more else 0\n        self.unpriv_mix_rate = 0 if unpriv_costs_more else (priv_cost - unpriv_cost) / (unpriv_trivial_cost - unpriv_cost)\n\n        return self\n\n    def predict(self, dataset, threshold=0.5):\n        \"\"\"Perturb the predicted scores to obtain new labels that satisfy\n        equalized odds constraints, while preserving calibration.\n\n        Args:\n            dataset (BinaryLabelDataset): Dataset containing `scores` that needs\n                to be transformed.\n            threshold (float): Threshold for converting `scores` to `labels`.\n                Values greater than or equal to this threshold are predicted to\n                be the `favorable_label`. Default is 0.5.\n        Returns:\n            dataset (BinaryLabelDataset): transformed dataset.\n        \"\"\"\n        if self.seed is not None:\n            np.random.seed(self.seed)\n\n        cond_vec_priv = utils.compute_boolean_conditioning_vector(\n            dataset.protected_attributes,\n            dataset.protected_attribute_names,\n            self.privileged_groups)\n        cond_vec_unpriv = utils.compute_boolean_conditioning_vector(\n            dataset.protected_attributes,\n            dataset.protected_attribute_names,\n            self.unprivileged_groups)\n\n        unpriv_indices = (np.random.random(sum(cond_vec_unpriv))\n                       <= self.unpriv_mix_rate)\n        unpriv_new_pred = dataset.scores[cond_vec_unpriv].copy()\n        unpriv_new_pred[unpriv_indices] = self.base_rate_unpriv\n\n        priv_indices = (np.random.random(sum(cond_vec_priv))\n                     <= self.priv_mix_rate)\n        priv_new_pred = dataset.scores[cond_vec_priv].copy()\n        priv_new_pred[priv_indices] = self.base_rate_priv\n\n        dataset_new = dataset.copy(deepcopy=True)\n\n        dataset_new.scores = np.zeros_like(dataset.scores, dtype=np.float64)\n        dataset_new.scores[cond_vec_priv] = priv_new_pred\n        dataset_new.scores[cond_vec_unpriv] = unpriv_new_pred\n\n        # Create labels from scores using a default threshold\n        dataset_new.labels = np.where(dataset_new.scores >= threshold,\n                                      dataset_new.favorable_label,\n                                      dataset_new.unfavorable_label)\n        return dataset_new\n\n    def fit_predict(self, dataset_true, dataset_pred, threshold=0.5):\n        \"\"\"fit and predict methods sequentially.\"\"\"\n        return self.fit(dataset_true, dataset_pred).predict(\n            dataset_pred, threshold=threshold)\n\n######### SUPPORTING FUNCTIONS ##########\n\ndef weighted_cost(fp_rate, fn_rate, cm, privileged):\n    norm_const = float(fp_rate + fn_rate) if\\\n                      (fp_rate != 0 and fn_rate != 0) else 1\n    return ((fp_rate / norm_const\n            * cm.generalized_false_positive_rate(privileged=privileged)\n            * (1 - cm.base_rate(privileged=privileged))) +\n           (fn_rate / norm_const\n            * cm.generalized_false_negative_rate(privileged=privileged)\n            * cm.base_rate(privileged=privileged)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:52:57.789675Z","iopub.execute_input":"2024-11-17T20:52:57.790236Z","iopub.status.idle":"2024-11-17T20:52:57.815311Z","shell.execute_reply.started":"2024-11-17T20:52:57.790186Z","shell.execute_reply":"2024-11-17T20:52:57.814441Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:52:57.816511Z","iopub.execute_input":"2024-11-17T20:52:57.816800Z","iopub.status.idle":"2024-11-17T20:52:57.852155Z","shell.execute_reply.started":"2024-11-17T20:52:57.816769Z","shell.execute_reply":"2024-11-17T20:52:57.851391Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"class CalibratedEqOdds:\n    def __init__(self):\n        self.thresholds = {}\n\n    def fit(self, y_true, y_pred, p_attr):\n        cm = confusion_matrix\n        tprs, fprs = {}, {}\n        \n        for group in torch.unique(p_attr):\n            group_mask = (p_attr == group)\n            y_true_group = y_true[group_mask]\n            y_pred_group = y_pred[group_mask]\n            tn, fp, fn, tp = cm(y_true_group, y_pred_group).ravel()\n            tprs[group.item()] = tp / (tp + fn)\n            fprs[group.item()] = fp / (fp + tn)\n\n        avg_tpr = sum(tprs.values()) / len(tprs)\n        avg_fpr = sum(fprs.values()) / len(fprs)\n        self.thresholds = {group: (avg_tpr, avg_fpr) for group in tprs.keys()}\n\n    def predict(self, y_prob, p_attr):\n        y_adjusted = y_prob.clone()\n        for i, prob in enumerate(y_prob):\n            group = p_attr[i].item()\n            tpr, fpr = self.thresholds[group]\n            #Adjust probabilities (example heuristic for postprocessing)\n            if prob > tpr:\n                y_adjusted[i] = 1\n            elif prob < fpr:\n                y_adjusted[i] = 0\n        return y_adjusted\n\n#Integrate postprocessing into testing pipeline\ndef test_model_with_postprocessing(model, test_loader, postprocessor, gpu_yes=True):\n    model.eval()  \n    if gpu_yes:\n        device = 'cuda'\n        model.to(device)\n    else:\n        device = 'cpu'\n        model.to(device)\n    \n    #Storage for calibration\n    y_true_list, y_pred_list, p_attr_list = [], [], []\n\n    #other metric calculations\n    correct, total = 0, 0\n    male_correct, female_correct = 0, 0\n    male_total, female_total = 0, 0\n    \n    #Initialize confusion matrix components for males and females\n    male_tp, male_fp, male_tn, male_fn = 0, 0, 0, 0\n    female_tp, female_fp, female_tn, female_fn = 0, 0, 0, 0\n    all_ones, all_zeros = 0, 0\n    \n    with torch.no_grad():\n        for images, labels, genders in test_loader:\n            images, labels, genders = images.to(device), labels.to(device), genders.to(device)\n            outputs = model(images)\n            probabilities = torch.softmax(outputs, dim=1)[:, 1]  #Probabilities for class 1\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n            \n            #Count total positive and negative cases\n            all_ones += (labels == 1).sum().item()\n            all_zeros += (labels == 0).sum().item()\n            \n            #Separate male and female predictions\n            male_mask = (genders == 1)\n            female_mask = (genders == 0)\n            \n            #Update accuracy counts\n            male_correct += (predicted[male_mask] == labels[male_mask]).sum().item()\n            female_correct += (predicted[female_mask] == labels[female_mask]).sum().item()\n            male_total += male_mask.sum().item()\n            female_total += female_mask.sum().item()\n            \n            #Update confusion matrix components for males\n            male_tp += ((predicted[male_mask] == 1) & (labels[male_mask] == 1)).sum().item()\n            male_fp += ((predicted[male_mask] == 1) & (labels[male_mask] == 0)).sum().item()\n            male_tn += ((predicted[male_mask] == 0) & (labels[male_mask] == 0)).sum().item()\n            male_fn += ((predicted[male_mask] == 0) & (labels[male_mask] == 1)).sum().item()\n            \n            #Update confusion matrix components for females\n            female_tp += ((predicted[female_mask] == 1) & (labels[female_mask] == 1)).sum().item()\n            female_fp += ((predicted[female_mask] == 1) & (labels[female_mask] == 0)).sum().item()\n            female_tn += ((predicted[female_mask] == 0) & (labels[female_mask] == 0)).sum().item()\n            female_fn += ((predicted[female_mask] == 0) & (labels[female_mask] == 1)).sum().item()\n\n            \n            #Store for calibration\n            y_true_list.extend(labels.cpu().numpy())\n            y_pred_list.extend(predicted.cpu().numpy())\n            p_attr_list.extend(genders.cpu().numpy())\n    \n    #Convert to tensors for postprocessing\n    y_true_tensor = torch.tensor(y_true_list)\n    y_pred_tensor = torch.tensor(y_pred_list)\n    p_attr_tensor = torch.tensor(p_attr_list)\n\n    #Calculate metrics\n    overall_accuracy = correct / total\n    male_accuracy = male_correct / male_total if male_total > 0 else 0\n    female_accuracy = female_correct / female_total if female_total > 0 else 0\n    \n    #Calculate TPR and FPR correctly\n    male_tpr = male_tp / (male_tp + male_fn) if (male_tp + male_fn) > 0 else 0\n    female_tpr = female_tp / (female_tp + female_fn) if (female_tp + female_fn) > 0 else 0\n    male_fpr = male_fp / (male_fp + male_tn) if (male_fp + male_tn) > 0 else 0\n    female_fpr = female_fp / (female_fp + female_tn) if (female_fp + female_tn) > 0 else 0\n    \n    #Fairness metrics\n    DEO = abs(male_tpr - female_tpr)\n    FPR_diff = abs(male_fpr - female_fpr)\n    \n    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n    print(f\"Male Accuracy: {male_accuracy:.4f}\")\n    print(f\"Female Accuracy: {female_accuracy:.4f}\")\n    print(f\"Male TPR: {male_tpr:.2f}\")\n    print(f\"Female TPR: {female_tpr:.2f}\")\n    print(f\"Male FPR: {male_fpr:.2f}\")\n    print(f\"Female FPR: {female_fpr:.2f}\")\n    print(f\"Equal Opportunity (EO): {DEO:.2f}\")\n    print(f\"False Positive Rate Difference (FPR): {FPR_diff:.2f}\")\n    \n    # Fit the postprocessor\n    postprocessor.fit(y_true_tensor, y_pred_tensor, p_attr_tensor)\n\n    # Adjust predictions using calibrated equalized odds\n    calibrated_preds = postprocessor.predict(y_pred_tensor, p_attr_tensor)\n\n    # Recompute metrics with adjusted predictions\n    overall_accuracy = (calibrated_preds == y_true_tensor).sum().item() / len(y_true_tensor)\n    print(f\"Overall Accuracy (Postprocessed): {overall_accuracy:.2f}\")\n\n    return overall_accuracy\n\n# Load your dataset and dataloaders\ntrain_loader, valid_loader, test_loader = get_loaders()\n\n# Instantiate the postprocessor\npostprocessor = CalibratedEqOdds()\n\n# Test the model with postprocessing\ntest_model_with_postprocessing(model, test_loader, postprocessor)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T21:03:44.663808Z","iopub.execute_input":"2024-11-17T21:03:44.664239Z","iopub.status.idle":"2024-11-17T21:04:05.227390Z","shell.execute_reply.started":"2024-11-17T21:03:44.664182Z","shell.execute_reply":"2024-11-17T21:04:05.226262Z"}},"outputs":[{"name":"stdout","text":"Using label attribute: Attractive\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Overall Accuracy: 0.8006\nMale Accuracy: 0.8161\nFemale Accuracy: 0.7908\nMale TPR: 0.65\nFemale TPR: 0.86\nMale FPR: 0.13\nFemale FPR: 0.33\nEqual Opportunity (EO): 0.21\nFalse Positive Rate Difference (FPR): 0.20\nOverall Accuracy (Postprocessed): 0.80\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"0.8005710850616171"},"metadata":{}}],"execution_count":26},{"cell_type":"markdown","source":"# Quantization","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Subset\nimport copy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:53:18.045025Z","iopub.execute_input":"2024-11-17T20:53:18.045394Z","iopub.status.idle":"2024-11-17T20:53:18.049987Z","shell.execute_reply.started":"2024-11-17T20:53:18.045358Z","shell.execute_reply":"2024-11-17T20:53:18.049107Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"num_calibration_samples = 1000  \ncalibration_indices = np.random.choice(len(test_loader.dataset), num_calibration_samples, replace=False)\ncalibration_subset = Subset(test_loader.dataset, calibration_indices)\ncalibration_dataloader = DataLoader(calibration_subset, batch_size=test_loader.batch_size, shuffle=False)\n\n#Clone the model to avoid modifying the original during quantization\nqmodel = models.quantization.resnet18()\nnum_features = qmodel.fc.in_features\nqmodel.fc = nn.Linear(num_features, 2)\n\n#Load the pretrained weights and make a safe copy of the model\nmodel_path = \"/kaggle/input/resnet18_baseline_celeba/pytorch/default/1/fine_tuned_best_ever_resnet18\"\nqmodel.load_state_dict(torch.load(model_path, weights_only = True))\nqmodel = copy.deepcopy(qmodel)\nqmodel.eval()\nqmodel.to('cpu')\n\n#Quantization steps\nqmodel.qconfig = torch.quantization.get_default_qconfig('fbgemm')\nqmodel_prepared = torch.quantization.prepare(copy.deepcopy(qmodel))\nqmodel_prepared.to('cpu')\n\n#Calibration\nprint(\"Caliberation results\\n\")\n\ndictionary_results_calibration, _ = test_model(qmodel_prepared, calibration_dataloader)\nqmodel_prepared.to('cpu')\n\n# # Convert to quantized model\n# qmodel_int8 = models.quantization.resnet18()\n# num_features = qmodel_int8.fc.in_features\n# qmodel_int8.fc = nn.Linear(num_features, 2)\n# qmodel_int8.to('cpu')\n\nqmodel_int8 = torch.quantization.convert(qmodel_prepared, inplace=True)\n\n# # Testing the quantized model\n# dict_, qmodel_int8 = test_model(qmodel_int8, test_loader,False)\n# dict_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:56:36.705511Z","iopub.execute_input":"2024-11-17T20:56:36.705946Z","iopub.status.idle":"2024-11-17T20:56:42.079736Z","shell.execute_reply.started":"2024-11-17T20:56:36.705907Z","shell.execute_reply":"2024-11-17T20:56:42.078706Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/ao/quantization/observer.py:221: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Caliberation results\n\nOverall Accuracy: 0.8010\nMale Accuracy: 0.8133\nFemale Accuracy: 0.79\nMale TPR: 0.68\nFemale TPR: 0.84\nMale FPR: 0.14\nFemale FPR: 0.30\nDemographic Equal Opportunity (DEO): 0.17\nFalse Positive Rate Difference (FPR): 0.16\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# qmodel_int8.to(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:53:19.294971Z","iopub.status.idle":"2024-11-17T20:53:19.295495Z","shell.execute_reply.started":"2024-11-17T20:53:19.295232Z","shell.execute_reply":"2024-11-17T20:53:19.295260Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader, valid_loader, test_loader = get_loaders()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:56:47.903536Z","iopub.execute_input":"2024-11-17T20:56:47.904316Z","iopub.status.idle":"2024-11-17T20:56:49.651696Z","shell.execute_reply.started":"2024-11-17T20:56:47.904274Z","shell.execute_reply":"2024-11-17T20:56:49.650784Z"}},"outputs":[{"name":"stdout","text":"Using label attribute: Attractive\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"postprocessor_ = CalibratedEqOdds()\n\n#Test the model with postprocessing\ntest_model_with_postprocessing(qmodel_int8, test_loader, postprocessor_,gpu_yes = False )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T20:56:50.160696Z","iopub.execute_input":"2024-11-17T20:56:50.161739Z","iopub.status.idle":"2024-11-17T20:58:40.381983Z","shell.execute_reply.started":"2024-11-17T20:56:50.161697Z","shell.execute_reply":"2024-11-17T20:58:40.380865Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Overall Accuracy: 0.7962\nMale Accuracy: 0.8215\nFemale Accuracy: 0.7802\nMale TPR: 0.61\nFemale TPR: 0.81\nMale FPR: 0.11\nFemale FPR: 0.28\nEqual Opportunity (EO): 0.21\nFalse Positive Rate Difference (FPR): 0.18\nOverall Accuracy (Postprocessed): 0.80\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"0.7961627091473801"},"metadata":{}}],"execution_count":25}]}